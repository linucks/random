{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ust coming to this quickly:\n",
    "\n",
    " \n",
    "\n",
    "We’ll also need columns for:\n",
    "\n",
    "    Final result\n",
    "        This will need to be “calculated”, probably just by giving reagent results priority over FTIR. However we had some cases this year where volunteers overstated the identification abilities of reagents, so we will need to manually review these before a final version.\n",
    "    Final result category\n",
    "        Every possible input for this (should be pretty limited, really) needs to be put into a lookup table to assign it a category\n",
    "    Soldas category\n",
    "        This will need a separate but very similar lookup table to the final result category\n",
    "    Unique ID\n",
    "        This should ideally use a similar format to last year. (SGP2017-0005)\n",
    "    SPSS Date           \n",
    "        As I recall, SPSS cannot handle standard date formats and needs to be given the US mm/dd/yy format.\n",
    "    Service user UID\n",
    "        This needs to be determined from whether a given intervention is attached to a “what was your first sample number at this event” value. These will need some level of manual review. I improved the data structure before Boomtown but others will probably need some context to sort out unfortunately.\n",
    "\n",
    " \n",
    "\n",
    "Really we are not working with a simple database but actually a 2d database where we have service users which could be linked to one or more sample numbers, and so if we are analysing social stats then we should be cautious about assuming every person only has one sample and vice versa when analysing lab data we should be cautious not to assume that every sample is a different person if it affects the outcome of a conclusion. I did a bit of reading about databases and how to set this up but given that I’m coming from using spreadsheets and the actual software side of a database vs a spreadsheet is new to me even if the concept isn’t, I haven’t gotten to a place where I could move to using a database program that’s designed to handle this sort of situation yet.\n",
    "\n",
    " \n",
    "\n",
    "Regarding orphans, I’ve just been through the Parklife data and found 17 FTIR results which had not been entered (so they were catalogued but appeared to have no FTIR). If this isn’t done at the end of the day then it needs to be done as part of the processing unfortunately, it would be a real shame to just lose these. We did it at the end of the day at boomtown and SW4.\n",
    "\n",
    " \n",
    "\n",
    "I think that’s all the processing considerations that come to mind for right now.\n",
    "\n",
    "Guy\n",
    "\n",
    "I have been through each of the events to add a “smart”\n",
    "\n",
    "    final outcome\n",
    "    second component detected\n",
    "\n",
    " \n",
    "\n",
    "column to the FTIR sheet in stats documents as this is how the other members of TEDI report (it would be a bit odd if we were never reporting a second component with our results, but sometimes the subtraction result that is given is garbage for pills (which later get reagent tested and turn out to most likely be just MDMA).\n",
    "\n",
    " \n",
    "\n",
    "I’ve also added these columns to the “catalog” worksheet tab in the statistics file of each event as I’ve been using that whenever I want to look at any lab data. I guess it won’t affect you.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Thanks Jens.\n",
    "\n",
    "Actually I’d even go as far as deleting that column (Substance(s) detected) altogether. It’s redundant if we have the other FTIR columns.\n",
    "\n",
    " \n",
    "\n",
    "These two entries are coming through because there are two possible fields to record the substance name (a limitation of google forms when using a dropdown list)\n",
    "\n",
    "other drug\n",
    "\n",
    "other drug or reasonable suggestion\n",
    "\n",
    "Any cells with this in them should be overwritten with data from the appropriate column for free text entry.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Anyway, I’ve been through the list and done all the important ones and most of the user entered stuff. I’ve ignored anything with a comma in it.\n",
    "\n",
    " \n",
    "\n",
    "Guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fix_sample_number(x):\n",
    "    \"\"\"Make sure all samples numbers are of form: AXXX (where A is one of A, F, W and X is a digit)\"\"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return x # leave NaN's alone\n",
    "    if (isinstance(x, str) or isinstance(x, unicode)) and len(x) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        sn = 'F{:04d}'.format(int(x))\n",
    "    except ValueError:\n",
    "        # Assume string so make sure it's of the right format\n",
    "        sn = str(x).strip().upper()\n",
    "    len_sn = len(sn)\n",
    "    if not ((len_sn == 5 and sn[0] in ['A', 'F', 'W', 'B']) or (len_sn == 6 and sn[0] == 'D')):\n",
    "        print(\"!!! Bad ID \\'%s\\'\" % sn)\n",
    "    return sn\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "\n",
    "def enumerate_duplicates(row):\n",
    "    \"\"\"Append a counter to duplicate labels\"\"\"\n",
    "    SEPARATOR = '.'\n",
    "    duplicates = {}\n",
    "    updated_row = []\n",
    "    for r in row:\n",
    "        count = duplicates.get(r, 0)\n",
    "        if count > 0:\n",
    "            label = \"{}{}{}\".format(r, SEPARATOR, count)\n",
    "        else:\n",
    "            label = r\n",
    "        updated_row.append(label)\n",
    "        duplicates[r] = count + 1\n",
    "    return updated_row\n",
    "\n",
    "# Need to define in main or we can't pickle the data objects\n",
    "class DataFrames(object):\n",
    "    def __init__(self):\n",
    "        self.catalog = None\n",
    "        self.ftir = None\n",
    "        self.reagent = None\n",
    "        self.mla = None\n",
    "        self.hr = None\n",
    "        self.combined = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = 'raise'\n",
    "\n",
    "def gsheets_service():\n",
    "    from googleapiclient.discovery import build\n",
    "    from httplib2 import Http\n",
    "    from oauth2client import file, client, tools\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    #Ensure that the creds file is always taken from the current working folder\n",
    "        #This allows two people on different PCs to merge changes more easily.\n",
    "    CREDS_FILE = os.path.join(os.path.realpath('./'),'JensDataExportJupyter_client_secret.json')\n",
    "    SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        import argparse\n",
    "        flags = argparse.ArgumentParser(parents=[tools.argparser]).parse_args([])\n",
    "        flow = client.flow_from_clientsecrets(CREDS_FILE, SCOPES)\n",
    "        creds = tools.run_flow(flow, store, flags)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "    return service\n",
    "\n",
    "def get_df(service, SPREADSHEET_ID, SS_RANGE, mla=False):\n",
    "    # Call the Sheets API\n",
    "    result = service.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                                range=SS_RANGE).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('*** No data found ***')\n",
    "        return None\n",
    "\n",
    "    # mla has irrelevant stuff in columns 1 and 3 and sample numbers in first column\n",
    "    if mla:\n",
    "        values.pop(0)\n",
    "        values.pop(1)\n",
    "        def not_blank(row):\n",
    "            return len(row[0]) > 0       \n",
    "    else:\n",
    "        def not_blank(row):\n",
    "            return sum(map(len, row[:6])) > 0\n",
    "\n",
    "    rows = list(filter(not_blank, values))\n",
    "    if not rows:\n",
    "        print('*** No data found after pruning rows! ***')\n",
    "        return None\n",
    "    \n",
    "    columns = enumerate_duplicates(rows[0])\n",
    "    ncols = len(rows[0])\n",
    "    row_max = max(map(len, rows[1:]))\n",
    "    width = min(ncols, row_max)\n",
    "    return pd.DataFrame(rows[1:], columns=columns[:width])\n",
    "\n",
    "def canonicalise_df(df, source=None):\n",
    "    \"\"\"Initial cleaning of all dataframes\"\"\"\n",
    "    #from pandas._libs.tslib import OutOfBoundsDatetime\n",
    "    if source:\n",
    "        print(\"Canonicalising %s\" % source)\n",
    "    # Standardise names\n",
    "    d = {\n",
    "        'Sample Code':'SampleNumber',\n",
    "        'Sample Number:':'SampleNumber',\n",
    "        'Sample Number':'SampleNumber',\n",
    "        'Sample number':'SampleNumber',\n",
    "        'Sample Num':'SampleNumber',\n",
    "        'Sample Number i.e F0XXX' : 'SampleNumber',\n",
    "        \n",
    "        'Sample Advertised/Acquired/Sold As' : 'SoldAs',\n",
    "        'Sample Sold As' : 'SoldAs',\n",
    "        'You submitted a substance for analysis. What were you told it was when you got it?':  'SoldAs',\n",
    "        \n",
    "        \n",
    "        'Sample Source' :'SampleSource',\n",
    "\n",
    "        'User Suspicion' :'UserSuspicion',\n",
    "\n",
    "        'Sample Form' :'SampleForm',\n",
    "\n",
    "        'Has the Service User or a close friend tried this batch?' : 'AlreadyTried',\n",
    "        'Had you already tried this substance before getting it tested?' : 'AlreadyTried',\n",
    "\n",
    "        'Your initials' : 'Tester',\n",
    "        'Your name and first initial' : 'Tester',\n",
    "        'Your name and surname initial' : 'Tester'\n",
    "    }\n",
    "    df.rename(columns=d, inplace=True)\n",
    "    \n",
    "    def fix_timestamp(x):\n",
    "        return pd.to_datetime(str(x), format='%d/%m/%Y %H:%M:%S')\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df.loc[:, 'Timestamp'] = df['Timestamp'].map(fix_timestamp)\n",
    "    df.loc[:, 'SampleNumber'] = df['SampleNumber'].apply(fix_sample_number)\n",
    "    df.dropna(subset=['SampleNumber'], inplace=True)\n",
    "    #df.sort_values(['Sample Number'], ascending=True, inplace=True)\n",
    "    # Make sure we don't have any blank columns\n",
    "    if set(df.columns.values).intersection(set([np.nan, ''])):\n",
    "        raise RuntimeError(\"Blank column names in Dataframe\")\n",
    "    return df\n",
    "\n",
    "def get_data(service, SPREADSHEET_ID):\n",
    "\n",
    "    CATALOG_RANGE = 'Catalog!A:R'\n",
    "    FTIR_RANGE = 'FTIR!A:X'\n",
    "    REAGENT_RANGE = 'Reagent!A:W'\n",
    "    MLA_RANGE = 'MLA!A:R'\n",
    "    HR_RANGE = 'Interventions!A:BJ'\n",
    "\n",
    "    df_catalog = get_df(service, SPREADSHEET_ID, CATALOG_RANGE)\n",
    "    df_catalog = canonicalise_df(df_catalog, source='catalog')\n",
    "    df_ftir = get_df(service, SPREADSHEET_ID, FTIR_RANGE)\n",
    "    df_ftir = canonicalise_df(df_ftir, source='ftir')\n",
    "    df_reagent = get_df(service, SPREADSHEET_ID, REAGENT_RANGE)\n",
    "    df_reagent = canonicalise_df(df_reagent, source='reagent')\n",
    "    df_mla = get_df(service, SPREADSHEET_ID, MLA_RANGE, mla=True)\n",
    "    df_mla = canonicalise_df(df_mla, source='mla')\n",
    "    try:\n",
    "        df_hr = get_df(service, SPREADSHEET_ID, HR_RANGE)\n",
    "    except ValueError:\n",
    "        df_hr = None\n",
    "    if df_hr is not None:\n",
    "        pass\n",
    "        df_hr = canonicalise_df(df_hr, source='hr')\n",
    "\n",
    "    df = DataFrames()\n",
    "    df.catalog = df_catalog\n",
    "    df.ftir = df_ftir\n",
    "    df.reagent = df_reagent\n",
    "    df.mla = df_mla\n",
    "    df.hr = df_hr\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script running from: /opt/random\n",
      "PROCESSING BOOMTOWN\n",
      "Canonicalising catalog\n",
      "!!! Bad ID 'TF0579'\n",
      "!!! Bad ID 'TF1665'\n",
      "!!! Bad ID 'TF1660'\n",
      "Canonicalising ftir\n",
      "!!! Bad ID 'TF1665'\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "!!! Bad ID 'FXXX'\n",
      "!!! Bad ID 'TF0653'\n",
      "!!! Bad ID 'TF1172'\n",
      "!!! Bad ID 'TF1762'\n",
      "PROCESSING BOARDMASTERS\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "PROCESSING MADE\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "!!! Bad ID 'XF0005'\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "PROCESSING SW4\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "PROCESSING LOST VILLAGE\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "PROCESSING BESTIVAL\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "!!! Bad ID 'P1000'\n",
      "!!! Bad ID 'F20005'\n",
      "!!! Bad ID 'G9998'\n",
      "PROCESSING YNOT\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "PROCESSING TRUCKFEST\n",
      "Canonicalising catalog\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "PROCESSING LSTD\n",
      "Canonicalising catalog\n",
      "!!! Bad ID 'S0050'\n",
      "!!! Bad ID 'M0120'\n",
      "!!! Bad ID 'M0141'\n",
      "!!! Bad ID 'M0204'\n",
      "!!! Bad ID 'S0186'\n",
      "!!! Bad ID 'S0202'\n",
      "Canonicalising ftir\n",
      "!!! Bad ID 'S0050'\n",
      "!!! Bad ID 'M0141'\n",
      "!!! Bad ID 'M0120'\n",
      "!!! Bad ID 'S0186'\n",
      "!!! Bad ID 'M0204'\n",
      "!!! Bad ID 'S0202'\n",
      "Canonicalising reagent\n",
      "!!! Bad ID 'S0050'\n",
      "Canonicalising mla\n",
      "!!! Bad ID 'M0120'\n",
      "Canonicalising hr\n",
      "PROCESSING KENDAL CALLING\n",
      "Canonicalising catalog\n",
      "!!! Bad ID 'M0011'\n",
      "Canonicalising ftir\n",
      "Canonicalising reagent\n",
      "Canonicalising mla\n",
      "Canonicalising hr\n",
      "PROCESSING PARKLIFE\n",
      "Canonicalising catalog\n",
      "!!! Bad ID 'M2248'\n",
      "Canonicalising ftir\n",
      "!!! Bad ID 'M2248'\n",
      "Canonicalising reagent\n",
      "!!! Bad ID 'NOT A1451'\n",
      "Canonicalising mla\n"
     ]
    }
   ],
   "source": [
    "#S how the folder where the code file is being run from        \n",
    "print(\"Script running from: %s\" % os.path.realpath(os.getcwd()))\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "BOOMTOWN2018_SPREADSHEET_ID = '1RiA-FwG_954Ger2VPsOSA3JLh-7sEoTYr40eVS0mp24'\n",
    "MADE2018_SPREADSHEET_ID = '1daXdyL6uL8qnMsEsP0RLZE9nDzt6J7Zr1ygQdguvi-E'\n",
    "BOARDMASTERS2018_SPREADSHEET_ID = '1U1lhUWLazDBN-wb2eZM8YV674f46npVfQK3XUVZjPow'\n",
    "SW42018_SPREADSHEET_ID = '1agpMmJ9XukeWXS5_mwrDSKeshUaFtYwOzsPiR1DKsPU'\n",
    "LOSTVILLAGE2018_SPREADSHEET_ID = '1OL0gyXrpZnJ8e7yR7eF6S2OaBYBiPDoVp5xGpdK4wlA'\n",
    "BESTIVAL2018_SPREADSHEET_ID = '184qudGcw4PB0SMtOo0ZBDtckeGaH0RCLUXbA-u3BiHE'\n",
    "YNOT2018_SPREADSHEET_ID = '1D01cj-Mra06TuoG_MsKuLq9OdtvKzrvRdiE255po_ag'\n",
    "TRUCKFEST2018_SPREADSHEET_ID = '1sGG9WJxKyD2CGUjzJAXul3g9hVnRz6HbTiqKV5cUAyA'\n",
    "LSTD2018_SPREADSHEET_ID = '1R8YqDnrhvuVMwPFShwaaAUIyCXQMeozA230OXsFsDQM'\n",
    "KENDALCALLING2018_SPREADSHEET_ID = '16-PfwBOaUxwod3X75LGk1VAjBblkNsTJpCsX825aghI'\n",
    "PARKLIFE2018_SPREADSHEET_ID = '1oO5sHcUhUn_7M1Hap73sOZHNEfWFMcDkQuWDRFf4d-w'\n",
    "\n",
    "\n",
    "data = {}\n",
    "service = gsheets_service()\n",
    "print(\"PROCESSING BOOMTOWN\")\n",
    "data['boomtown'] = get_data(service, BOOMTOWN2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING BOARDMASTERS\")\n",
    "data['boardmasters'] = get_data(service, BOARDMASTERS2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING MADE\")\n",
    "data['made'] = get_data(service, MADE2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING SW4\")\n",
    "data['sw4'] = get_data(service, SW42018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING LOST VILLAGE\")\n",
    "data['lostvillage'] = get_data(service, LOSTVILLAGE2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING BESTIVAL\")\n",
    "data['bestival'] = get_data(service, BESTIVAL2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING YNOT\")\n",
    "data['ynot'] = get_data(service, YNOT2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING TRUCKFEST\")\n",
    "data['truckfest'] = get_data(service, TRUCKFEST2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING LSTD\")\n",
    "data['lstd'] = get_data(service, LSTD2018_SPREADSHEET_ID)\n",
    "print( \"PROCESSING KENDAL CALLING\")\n",
    "data['kc'] = get_data(service, KENDALCALLING2018_SPREADSHEET_ID)\n",
    "print(\"PROCESSING PARKLIFE\")\n",
    "data['parklife'] = get_data(service, PARKLIFE2018_SPREADSHEET_ID)\n",
    "\n",
    "with open('foo_multi.pkl','wb') as w:\n",
    "    pickle.dump(data, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('foo_multi.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Need to define in main or we can't pickle the data objects\n",
    "class Duplicates(object):\n",
    "    def __init__(self, dfs):\n",
    "        self.dfs = dfs\n",
    "        dtypes = ['catalog', 'ftir', 'reagent', 'mla', 'hr']\n",
    "        for t in dtypes:\n",
    "            setattr(self, t, None)\n",
    "        for t in dtypes:\n",
    "            self.find_duplicates(t)\n",
    "        \n",
    "    def find_duplicates(self, dtype):\n",
    "        dataframe = getattr(self.dfs, dtype)\n",
    "        if dataframe is None:\n",
    "            return\n",
    "        duplicates = dataframe['SampleNumber'].duplicated()\n",
    "        if duplicates.any():\n",
    "            duplicates = list(dataframe.loc[duplicates, 'SampleNumber'].values)\n",
    "            print(\"### %d duplicated %s SampleNumbers %s ###\" % (len(duplicates), dtype, duplicates))\n",
    "#             dataframe[datafra,e['SampleNumber'].duplicated(keep=False)].to_csv('{}_duplicates.csv'.format(dtype))\n",
    "        else:\n",
    "            duplicates = None\n",
    "        setattr(self, dtype, duplicates)\n",
    "        \n",
    "    def has_hr_duplicates(self):\n",
    "        if self.hr:\n",
    "            outs = 'Please fix HR duplicates'\n",
    "            print(outs)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Orphans(object):\n",
    "    def __init__(self, dataframes):\n",
    "        self.catalog = None\n",
    "        self.ftir = None\n",
    "        self.reagent = None\n",
    "        self.mla = None\n",
    "        self.hr = None\n",
    "        self.ftir_missing = None\n",
    "        \n",
    "        self.find_unique(dataframes)\n",
    "        \n",
    "    def find_unique(self, dataframes):\n",
    "        # Check there are no SampleNumbers in any of the other spreadsheets that aren't in the cataolog sheet\n",
    "        catalog_unique = set(dataframes.catalog['SampleNumber'].unique())\n",
    "        \n",
    "        ftir_unique = set(dataframes.ftir['SampleNumber'].unique())\n",
    "        self.ftir = ftir_unique.difference(catalog_unique)\n",
    "\n",
    "        reagent_unique = set(dataframes.reagent['SampleNumber'].unique())\n",
    "        self.reagent = reagent_unique.difference(catalog_unique)\n",
    "\n",
    "        self.hr = None\n",
    "        hr_unique = None\n",
    "        if dataframes.hr is not None:\n",
    "            hr_unique = set(dataframes.hr['SampleNumber'].unique())\n",
    "            # HR need to be both in catalog and ftir\n",
    "            self.hr = hr_unique.difference(ftir_unique.union(catalog_unique))\n",
    "\n",
    "        mla_unique = set(dataframes.mla['SampleNumber'].unique()).difference(catalog_unique)\n",
    "        self.mla = mla_unique.difference(catalog_unique)\n",
    "\n",
    "        # Check for any that are only in the catalog\n",
    "        unique = [u for u in [ftir_unique, reagent_unique, hr_unique, mla_unique] if u is not None]\n",
    "        outside_catalog = set.union(*unique)\n",
    "        self.catalog = catalog_unique.difference(outside_catalog)\n",
    "\n",
    "        # Check for any that aren't in FTIR and don't have anything in reagent test\n",
    "        self.ftir_missing = catalog_unique.difference(ftir_unique).difference(reagent_unique).difference(self.catalog)\n",
    "\n",
    "            \n",
    "    def print_orphans(self):\n",
    "        if self.catalog:\n",
    "            print(\"Orphaned Catalog SampleNumbers: %s\" % sorted(self.catalog))\n",
    "        if self.ftir:\n",
    "            print(\"Orphaned FTIR SampleNumbers: %s\" % sorted(self.ftir))\n",
    "        if self.mla:\n",
    "            print(\"Orphaned MLA SampleNumbers: %s\" % sorted(self.mla))\n",
    "        if self.hr:\n",
    "            print(\"Orphaned HR SampleNumbers: %s\" % sorted(self.hr))\n",
    "        if self.ftir_missing:\n",
    "            print(\"Samples not in FTIR or Reagent: %s\" % sorted(self.ftir_missing))          \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Summary Cell\n",
    "catalog_orphan = 0\n",
    "ftir_orphan = 0\n",
    "hr_orphan = 0\n",
    "catalog_duplicates = 0\n",
    "ftir_duplicates = 0\n",
    "hr_duplicates = 0\n",
    "hr = 0\n",
    "for festival, fdfs in data.items():\n",
    "    print(\"\\n{} Festival: {}{} \".format(\"=\"* 15, festival, \"=\"*15))\n",
    "    orphans = Orphans(fdfs)\n",
    "    orphans.print_orphans()\n",
    "    catalog_orphan += len(orphans.catalog)\n",
    "    ftir_orphan += len(orphans.ftir)\n",
    "    if orphans.hr is not None:\n",
    "        hr_orphan += len(orphans.hr)\n",
    "    catalog_duplicates += sum(list(map(lambda x: x.startswith('D'), fdfs.catalog['SampleNumber'].values)))\n",
    "    ftir_duplicates += sum(list(map(lambda x: x.startswith('D'), fdfs.ftir['SampleNumber'].values)))\n",
    "    if fdfs.hr is not None:\n",
    "        hr_duplicates += sum(list(map(lambda x: x.startswith('D'), fdfs.hr['SampleNumber'].values)))\n",
    "    if fdfs.hr is not None:\n",
    "        hr += len(fdfs.hr)\n",
    "\n",
    "print(\"=\" * 30)\n",
    "print(\"SUMMARY\")\n",
    "print(\"Catalog duplicates \", catalog_duplicates)\n",
    "print(\"FTIR duplicates \", ftir_duplicates)\n",
    "print(\"HR duplicates \", hr_duplicates)\n",
    "print(\"Catalog orphan \", catalog_orphan)\n",
    "print(\"FTIR orphan \", ftir_orphan)\n",
    "print(\"HR orphan \", hr_orphan)\n",
    "\n",
    "print(\"Total number HR interventions \", hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge of all data\n",
    "# import pickle\n",
    "# with open('foo_multi.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "for festival, dfs in data.items():\n",
    "    # Rename columns to identify source dataframe\n",
    "    dfs.catalog.columns = ['catalog_'+ name if name != 'SampleNumber' else name for name in dfs.catalog.columns]\n",
    "    dfs.ftir.columns = ['ftir_'+ name if name != 'SampleNumber' else name for name in dfs.ftir.columns]\n",
    "    dfs.mla.columns = ['mla_'+ name if name != 'SampleNumber' else name for name in dfs.mla.columns]\n",
    "    if dfs.hr is not None:\n",
    "        dfs.hr.columns = ['hr_'+ name if name != 'SampleNumber' else name for name in dfs.hr.columns]\n",
    "\n",
    "    # Remove all but the last of any duplicate SampleNumber\n",
    "    # want a list of all but the last duplicates\n",
    "    mask = ~dfs.catalog['SampleNumber'].duplicated(keep=False) | ~dfs.catalog['SampleNumber'].duplicated(keep='last')\n",
    "    dfs.catalog = dfs.catalog[mask]\n",
    "    mask = ~dfs.ftir['SampleNumber'].duplicated(keep=False) | ~dfs.ftir['SampleNumber'].duplicated(keep='last')\n",
    "    dfs.ftir = dfs.ftir[mask]\n",
    "    mask = ~dfs.mla['SampleNumber'].duplicated(keep=False) | ~dfs.mla['SampleNumber'].duplicated(keep='last')\n",
    "    dfs.mla = dfs.mla[mask]\n",
    "    if dfs.hr is not None:\n",
    "        mask = ~dfs.hr['SampleNumber'].duplicated(keep=False) | ~dfs.hr['SampleNumber'].duplicated(keep='last')\n",
    "        dfs.hr = dfs.hr[mask]\n",
    "\n",
    "    # First outer join on catalog/ftir to make sure we collect all possible information - this will result in\n",
    "    # some rows where there was no catalog data, only ftir data, but this is ok as when we merge with hr we will\n",
    "    # throw away any row that doesn't have a corresponding sample number in HR. This was even if catalog data is\n",
    "    # missing, we still get the FTIR data, which may be enough for our purposes\n",
    "    df_all = pd.merge(dfs.catalog, dfs.ftir, how='outer', on=['SampleNumber'])\n",
    "    # Add in mla data - only for when there are existing sample numbers\n",
    "    df_all = pd.merge(df_all, dfs.mla, how='left', on=['SampleNumber'])\n",
    "    if dfs.hr is not None:\n",
    "        # inner join -> merge only where there are matching sample numbers\n",
    "        df_all = pd.merge(df_all, dfs.hr, how='inner', on=['SampleNumber'])\n",
    "    dfs.combined = df_all\n",
    "    \n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning 'Sample form' field at 07/11/18 21:51:18\n"
     ]
    }
   ],
   "source": [
    "# This cell cleans the \"sample form\" field \n",
    "def clean_sample_form(df):\n",
    "    sample_form_d = { 'pill' : ['Ecstasy Tablet',\n",
    "                                'ecstasy pill',\n",
    "                                'ecstacy pill',\n",
    "                                'Non-pharmaceutical tablet (ecstasy etc)',\n",
    "                                'other recreational pill',\n",
    "                                 'Whole pill',\n",
    "                                'Other pill',\n",
    "                                'Pharmaceutical'],\n",
    "                      'partial pill' : ['Partial ecstasy pill',\n",
    "                                        'Partial 2C-B pill',\n",
    "                                        'Crushed tablet'],\n",
    "                      'powder' : ['powder/capsule/bomb',\n",
    "                                  'Powder/capsule/bomb/crystal',\n",
    "                                  'Powder or crushed pill',\n",
    "                                  'Crystal, Capsule or Powder'],\n",
    "                      'liquid' : ['*Cannabinoid liquid',\n",
    "                                   '*Viscous liquid',\n",
    "                                  'Dissolved in Propylene Glycol',\n",
    "                                  'Oil'],\n",
    "                       'tab' : ['blotter', 'LSD Tab']\n",
    "                      }\n",
    "\n",
    "\n",
    "    # Firstly convert all columns to lower case and remove any spaces\n",
    "    def lower(value):\n",
    "        if type(value) is str:\n",
    "            value = value.strip().lower()\n",
    "        return value\n",
    "\n",
    "    for column in ['SampleForm']:\n",
    "        df[column] = df[column].map(lower, na_action='ignore')\n",
    "    \n",
    "    replace_d = {}\n",
    "    for column in ['SampleForm']:\n",
    "        replace_d[column] = {}\n",
    "        for drug, names in sample_form_d.items():\n",
    "            for name in names:\n",
    "                replace_d[column][name.lower()] = drug\n",
    "    \n",
    "    # Replace values\n",
    "    df.replace(replace_d, inplace=True)\n",
    "    return df\n",
    "    \n",
    "dfs.catalog = clean_sample_form(dfs.catalog)\n",
    "dfs.ftir = clean_sample_form(dfs.ftir)\n",
    "dfs.reagent = clean_sample_form(dfs.reagent)\n",
    "print(\"Finished cleaning 'Sample form' field at %s\" % now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1 alpha alpha alpha trifluoro m tolyl piperazine': 'TFMPP', '2-cb': '2c-b', '2-ce': '2c-e', '250mg mdma': 'MDMA', '25i': '25i-nbome', '25i 3 year': '25i-nbome', '25i-nbome': '25i-nbome', '2c-b': '2c-b', '2c-b (or 2c-b derivative such as 2ci)': '2c-b', '2c-b-fly': '2c-b-fly', '2c-e': '2c-e', '2c/b': '2c-b', '2cb': '2c-b', '2cb pill': '2c-b', '2ce,': '2C-E', '2ci': '2C-I', '3-meo-pcp': '3-meo-pcp', '3meo pcp': '3-meo-pcp', '4-chloroethcathinone': '4-CEC', '4-ho-met,': '4-HO-MET', '4fa': '4-FA', 'aderol': 'amphetamine', 'amphetamine': 'amphetamine', 'asborbic acid (vitamin c)': 'vitamin C', 'ascorbic acid (vitamin c)': 'vitamin c', 'bag that was found': 'found', 'baking powder': 'sodium bicarbonate', 'baking power': 'sodium bicarbonate', 'baking soda (sodium bicarbonate)': 'sodium bicarbonate', 'caffeine': 'caffeine', 'chloroquine': 'chloroquine', 'chloroquine confirm with reagent test': 'chloroquine', 'choroquine': 'chloroquine', 'coacaine': 'cocaine', 'coc': 'cocaine', 'cocaime': 'cocaine', 'cocain': 'cocaine', 'cocaine': 'cocaine', 'cociane': 'cocaine', 'coke': 'cocaine', 'coke - strong': 'cocaine', 'coke suspected': 'cocaine', 'crack - 2 months': 'cocaine', 'crck': 'cocaine', 'creatine': 'creatine', 'creatine (nutritional supplement)': 'creatine', 'crystal meth': 'crystal meth', 'dk': 'unknown', 'dont know': 'unknown', 'dontknow': 'unknown', 'donald trump pill': 'MDMA', 'ecstacy': 'MDMA', 'ecstacy pill': 'MDMA', 'ecstacy pill transformer': 'MDMA', 'ecstasy': 'MDMA', 'ecstasy (mdma)': 'MDMA', 'ecstasy -mdma': 'MDMA', 'ecstasy pill': 'MDMA', 'ecstasy pill (mdma)': 'MDMA', 'ecstasy pill - 90s / dinosaur': 'MDMA', 'ecstasy pill orange tesla': 'MDMA', 'ecstasy pill with mdma': 'MDMA', 'ecstasy tablet': 'MDMA', 'ectasy': 'MDMA', 'ectasy pill': 'MDMA', 'ecty': 'MDMA', 'escasy': 'MDMA', 'escasy tablet': 'MDMA', 'esctacy partial pill fanta': 'MDMA', 'estasy': 'MDMA', 'ethylone': 'ethylone', 'extasy pill': 'MDMA', 'found': 'found', 'found (mdma suspicion)': 'found', 'found - but suspected mdma based on smell': 'found', 'found bag': 'found', 'found it': 'found', 'found it - no idea': 'found', 'found it on site': 'found', 'found it. thought it was cocaine': 'found', 'found it. unknown': 'found', 'found on beach': 'found', 'found on floor': 'found', 'found on the floor': 'found', 'found pill': 'found', 'found pills looked them up either mdma or tramadol': 'found', 'found powder': 'found', 'found substance': 'found', 'found them': 'found', 'found unknown': 'found', 'full pill green heniken': 'MDMA', 'full pill lv': 'MDMA', 'full pill mdma': 'MDMA', 'full pill pink redbull': 'MDMA', 'full pill pink transformer': 'MDMA', 'full pill yellow lego man': 'MDMA', 'ghb': 'ghb', 'ghb 2mionths': 'ghb', 'ket': 'ketamine', 'ketaine': 'ketamine', 'ketamin': 'ketamine', 'ketamine': 'ketamine', 'ketamne': 'ketamine', 'ketaqmine': 'ketamine', 'ketemin': 'ketamine', 'ketmain': 'ketamine', 'ketmaine': 'ketamine', 'ketmine': 'ketamine', 'ketsmine': 'ketamine', 'lsd': 'lsd', 'lsd - blotter': 'lsd', 'lsd blotter': 'lsd', 'lsd tab': 'lsd', 'mda': 'MDA', 'mda;': 'MDA', 'mdma': 'mdma', 'mdma  pill': 'mdma', 'mdma (pill)': 'mdma', 'mdma (pills)': 'mdma', 'mdma (powder)': 'mdma', 'mdma (stone island) pill': 'mdma', 'mdma - pill': 'mdma', 'mdma - pill powder': 'mdma', 'mdma 210mg': 'mdma', 'mdma cristal': 'mdma', 'mdma crysral': 'mdma', 'mdma crystal': 'mdma', 'mdma crystal/ powder': 'mdma', 'mdma crystals': 'mdma', 'mdma crystsl': 'mdma', 'mdma crytal': 'mdma', 'mdma or viagra': 'mdma', 'mdma partial pill': 'mdma', 'mdma pil': 'mdma', 'mdma pill': 'mdma', 'mdma pill louis vuitton': 'mdma', 'mdma pill - bitcoin': 'mdma', 'mdma pill - blue emoji': 'mdma', 'mdma pill - ea sports': 'mdma', 'mdma pill - ea7': 'mdma', 'mdma pill - green dice': 'mdma', 'mdma pill - green emoji': 'mdma', 'mdma pill - green premier league': 'mdma', 'mdma pill - manchester united': 'mdma', 'mdma pill - octagan': 'mdma', 'mdma pill - purple tomorrowland': 'mdma', 'mdma pill - rolls royce': 'mdma', 'mdma pill - silver bar': 'mdma', 'mdma pill - unknown brand red pill': 'mdma', 'mdma pill -sound cloud pill': 'mdma', 'mdma pill / partial sample': 'mdma', 'mdma pill crumbles': 'mdma', 'mdma pills': 'mdma', 'mdma powder': 'mdma', 'mdma powder/ crystal': 'mdma', 'mdma powder/crystal': 'mdma', 'mdma power': 'mdma', 'mdma precursor': 'mdma', 'mdma tablet': 'mdma', 'mdma tomorrowland pill': 'mdma', 'mdma transformer pill': 'mdma', 'mdma wait for reagent test': 'mdma', 'mdma with benzocaine': 'mdma', 'mdma with minor caffeine impurities': 'mdma', 'mdma with possible crushed up pill in bag': 'mdma', 'mdma+mda': 'mdma', 'mdma- pill': 'mdma', 'mdma/mix': 'mdma', 'mdmda': 'mdma', 'medafonil': 'Modafinil', 'monosodium glutamate': 'monosodium glutamate', 'monosodium glutamate (msg - food additive)': 'monosodium glutamate', 'monosodium glutamate (msg)': 'monosodium glutamate', 'msg': 'monosodium glutamate', 'mxe': 'mxe', 'n-ethyl pentalone': 'n-ethylpentylone', 'n-ethyl pentylone': 'n-ethylpentylone', 'n-ethyl-pentylone': 'n-ethylpentylone', 'n-ethylpentalone': 'n-ethylpentylone', 'n-ethylpentylone': 'n-ethylpentylone', 'no active component': 'no active component identified', 'no active component identified': 'no active component identified', 'no active component via ir': 'no active component identified', 'no active compound - reagent test': 'no active component identified', 'no active compounds': 'no active component identified', 'no active ingredient': 'no active component identified', 'no active substance': 'no active component identified', 'no active substance detected (is plaster of paris)': 'no active component identified', 'no active substance identified': 'no active component identified', 'no active substances - reagent test': 'no active component identified', 'no compound detected': 'no active component identified', 'no compound detected yet': 'no active component identified', 'no compound in our database': 'no active component identified', 'no drug substance detected (plaster of paris)': 'no active component identified', 'no match': 'no active component identified', 'no substance detected': 'no active component identified', 'none': 'no active component identified', 'not known': 'unknown', 'not known - found it': 'found', 'nothing': 'no active component identified', 'nothing - reagent test': 'no active component identified', 'nothing by ir': 'no active component identified', 'paracetamol': 'paracetamol', 'paracetemol': 'paracetamol', 'parcial pill': 'MDMA', 'part pill pink red bull': 'MDMA', 'partial mdma pill': 'MDMA', 'partial pill': 'MDMA', 'partial pill (blue punisher)': 'MDMA', 'partial pill ?': 'MDMA', 'partial pill dr. who': 'MDMA', 'partial pill found it': 'MDMA', 'partial pill ghost buster': 'MDMA', 'partial pill gold bar': 'MDMA', 'partial pill green turtle': 'MDMA', 'partial pill rolls royce': 'MDMA', 'pill': 'MDMA', 'pill - mdma': 'MDMA', 'pill - pece & love': 'MDMA', 'pill binder': 'MDMA', 'pill chubachub': 'MDMA', 'pill duracell': 'MDMA', 'pill e / mdma': 'MDMA', 'pill mdma': 'MDMA', 'pill neon green barcelona football club': 'MDMA', 'pill square green': 'MDMA', 'pill superman': 'MDMA', 'pill/mdma': 'MDMA', 'plaster of paris': 'plaster of paris', 'plaster of paris (concrete)': 'plaster of paris', 'plaster of paris and chalk': 'plaster of paris', 'plaster of paris(chalk)': 'plaster of paris', 'plater of paris': 'plaster of paris', 'popper (solvent)': 'poppers', 'poppers': 'poppers', 'poppers - yesterday': 'poppers', 'punisher pill': 'MDMA', 'silver bar': 'MDMA', 'sold as mdma': 'MDMA', 'sucrose': 'Sugar', 'sugar': 'Sugar', 'sugar (tang fruit squash mix)': 'Sugar', 'tfmpp (piperazine)': 'TFMPP', 'the punisher mdma': 'MDMA', 'uknown': 'unknown', 'unknoen': 'unknown', 'unknown': 'unknown', 'unknown - found': 'unknown', 'unknown - reagent test': 'unknown', 'unknown cathnone (irgacure)': 'unknown', 'unknown from ir test': 'unknown', 'unknown pill': 'unknown', 'unknown powder - found on floor maybe cocaine': 'unknown', 'unknown sold as cocaine': 'unknown', 'unknown substance': 'unknown', 'unkown': 'unknown', 'unsure': 'unknown', 'unsure (found substance)': 'found', 'xanac': 'xanax', 'xanax': 'xanax', 'xtc': 'MDMA', 'xtc crytl': 'MDMA', 'xtc power': 'MDMA', 'yellow ace - partial pill': 'MDMA'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural yellow 11': 'Binder', '1 alpha alpha alpha trifluoro m tolyl piperazine': 'TFMPP', '2c-b': '2C-B', '3,4-methylenedioxyamphetamine': 'MDA', '3-meo-pcp': '3-meo-pcp', '4-cec': '4-chloroethcathinone', '4-chloroethcathinone': '4-chloroethcathinone', '4-me-dimethylcathinone': '4-me-dimethylcathinone', '4-methyl-n-ethylpentedrone (4-methyl-nep)': '4-methyl-n-ethylpentedrone (4-methyl-nep)', '5-meo-mipt': '5-meo-mipt', '6-apb': '6-apb', 'alprazolam': 'Alprazolam', 'amphetamine': 'Amphetamine', 'ascorbic  acid': 'Ascorbic acid', 'ascorbic acid - vitamin c': 'Ascorbic acid', 'benzocaine': 'Benzocaine', 'bk-dmbdb': 'bk-dmbdb', 'boron trioxide': 'Boric Acid', 'caffeine': 'caffeine', 'caffiene': 'caffeine', 'cathinone (n-ethylamino-hexanophenone)': 'Hex-en', 'chloroquine': 'chloroquine', 'cocaine': 'cocaine', 'coconut oil': 'Coconut oil', 'coryzalia': 'coryzalia', 'creatine': 'creatine', 'dibenzoyl peroxide': 'dibenzoyl peroxide', 'dicyclohexyl phthalate': 'dicyclohexyl phthalate', 'dimethyl sulfone': 'Methylsulfonylmethane', 'dob': 'DOB', 'ghb': 'GHB', 'hammerite metal paint': 'No active component identified', 'hash': 'Hash', 'hydroxychloroquinone': 'Chloroquine', 'irgacure 907': 'irgacure 907', 'irgacure 907 (cacure)': 'irgacure 907', 'irgacure 907 (morpholine cathinone)': 'irgacure 907', 'ketamine': 'ketamine', 'lactose': 'Binder', 'levamisole': 'levamisole', 'levimasole': 'levamisole', 'lipoic acid': 'Lipoic acid', 'mannitol': 'mannitol', 'mdma': 'mdma', 'mdma precursor': 'mdma', 'mdma precursor impurity': 'mdma', 'mephedrone': 'mephedrone', 'mexedrone': 'mexedrone', 'monosodium glutamate': 'monosodium glutamate', 'monosodium glutamate (msg)': 'monosodium glutamate', 'morpholine cathinone': 'monosodium glutamate', 'msg': 'monosodium glutamate', 'n-ethylpentylone': 'n-ethylpentylone', 'n-pentylone': 'n-ethylpentylone', 'no active component identified': 'no active component identified', 'no match': 'no active component identified', 'no match (but spectrum indicates organic molecule)': 'no match (but spectrum indicates organic molecule)', 'not lsd': 'Not LSD', 'other': 'no active component identified', 'other drug': 'Check \"other\" field', 'other drug or reasonable suggestion': 'Check \"other\" field', 'paracetamol': 'paracetamol', 'parexyl': 'binder', 'pentylone': 'Pentylone', 'phenacetin': 'Phenacetin', 'pill binder': 'binder', 'plaster of paris': 'plaster of paris', 'procaine': 'Procaine', 'pseudoepedrine': 'pseudoephedrine', 'pyridoxine': 'vitamin b6', 'quinine': 'Quinnine', 'sassafras oil': 'MDMA', 'sildenafil': 'Sildenafil', 'sodium bicarbonate': 'sodium bicarbonate', 'sugar': 'sugar', 'table salt': 'Salt', 'taurine': 'Taurine', 'tfmpp': 'TFMPP', 'thc-a': 'THC', 'unidentified cutting agent': 'unidentified cutting agent', 'unknown organic': 'no match (but spectrum indicates organic molecule)', 'vitamin b6': 'vitamin b6', 'water': 'Water'}\n"
     ]
    }
   ],
   "source": [
    "# Get the drugs map\n",
    "if 'service' not in locals():\n",
    "    service = gsheets_service()\n",
    "sheet_id = '1CgqTjdKizat-g7K7-AAuVIazQFKJ3WAAPHR-Qpa49lU'\n",
    "ss_range = 'FastUserdrugsMap!A:B'\n",
    "result = service.spreadsheets().values().get(spreadsheetId=sheet_id,\n",
    "                                            range=ss_range).execute()\n",
    "values = result.get('values', [])\n",
    "assert values[0] == ['Drug name', 'Translation']\n",
    "user_drugs_map = { dt[0] : dt[1] for dt in values[1:] if len(dt) == 2 }\n",
    "print(user_drugs_map)\n",
    "\n",
    "ss_range = 'FastTesterdrugsMap!A:B'\n",
    "result = service.spreadsheets().values().get(spreadsheetId=sheet_id,\n",
    "                                            range=ss_range).execute()\n",
    "values = result.get('values', [])\n",
    "tester_drugs_map = { dt[0] : dt[1] for dt in values[1:] if len(dt) == 2 }\n",
    "print(tester_drugs_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPHETAMINE = 'amphetamine'\n",
    "BENZODIAZEPINE = 'benzodiazepine'\n",
    "COCAINE = 'cocaine'\n",
    "FOUND = 'found'\n",
    "KETAMINE = 'ketamine'\n",
    "LSD = 'lsd'\n",
    "MEPHEDRONE = 'mephedrone'\n",
    "MDMA = 'mdma'\n",
    "NETHYLPENTYLONE = 'n-ethylpentylone'\n",
    "PSYCHEDELIC = 'psychedelic'\n",
    "TWOCB = '2cb'\n",
    "UNKNOWN = 'unknown'\n",
    "\n",
    "drugs_map = { \n",
    "    AMPHETAMINE : ['speed', 'Speed', 'base/speed', 'adderall'],\n",
    "    BENZODIAZEPINE : ['chinese valium', ],\n",
    "    COCAINE : ['coke', 'cut cocaine'],\n",
    "    FOUND : ['unknow found'],\n",
    "    KETAMINE : ['?ket', '/ketamie', 'maybe ketamine?', 'katamine', 'vanila ketamine', \n",
    "                'vetamine', 'not mdma. ketamine?', 'ketamoine'],\n",
    "    LSD : ['acid', 'liquid lsd'],\n",
    "    MEPHEDRONE : ['meow meow', 'mcat'],\n",
    "    MDMA : ['mdxx', 'mda/mdea/mdma', 'mdma,', 'mandy', 'probaby mdma', 'mdma?', 'mdma with caffeine',\n",
    "           '3/4 of pill green shooting star', 'ecstacy', 'ecstacy pill', 'ecstasy',\n",
    "            'ecstasy pill', 'esctacy pill sample', 'estacy pill', 'pill'],\n",
    "    #NETHYLPENTYLONE : ['n-ethylpentylone'],\n",
    "    PSYCHEDELIC : [ '4-aco dmt', '4-aco-dmt', '4aco', '4acodmt', '5meomipit', 'dmt_2cb', 'dmt', 'ayahuasca'],\n",
    "    TWOCB : ['2 cb', '2c-b'],\n",
    "    UNKNOWN : ['unknown pill', 'unsure', 'unsure - maybe dmt', 'unsure of content', \n",
    "               'no effect', 'no idea', 'data missing', ''],   \n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Strength\" of powdered substance\n",
      "% MDMA content\n",
      "Actual filename\n",
      "After hearing today’s test results & advice, what do you plan to do?\n",
      "After our conversation today, would you like to have any further advice or support from a treatment service for your alcohol or drug use?\n",
      "Age\n",
      "AlreadyTried\n",
      "AlreadyTried_x\n",
      "AlreadyTried_y\n",
      "Analysis required\n",
      "Are you currently taking any \"Over the Counter\" medication?\n",
      "Are you currently taking any prescribed medication?\n",
      "Brief Note\n",
      "Brief Note.1\n",
      "Colour\n",
      "Compound detected\n",
      "Compound detected (Subtraction)\n",
      "DRINK 1 - Type\n",
      "DRINK 1: Quantity\n",
      "DRINK 1: Vessel (focus on size not drink type)\n",
      "DRINK 2 - Type\n",
      "DRINK 2: Quantity\n",
      "DRINK 2: Vessel (focus on size not drink type)\n",
      "DRINK 3 - Type\n",
      "DRINK 3: Quantity\n",
      "DRINK 3: Vessel (focus on size not drink type)\n",
      "DRINK 4 - Type\n",
      "DRINK 4: Quantity\n",
      "DRINK 4: Vessel (focus on size not drink type)\n",
      "Do you have any concerns about how you are feeling at the moment?\n",
      "Do you trust the supplier of this substance (in terms of the substance)?\n",
      "Does the substance detected match the substance that was advertised?\n",
      "Dried Mass\n",
      "Dried weight w/ paper\n",
      "Dry Mass (mg)\n",
      "Dry mass (mg)\n",
      "Duplicate finder\n",
      "Ethnicity\n",
      "FTIR\n",
      "Final actual file name\n",
      "Formulaic File Name\n",
      "Fraction washed\n",
      "Gender\n",
      "HR Workers Name\n",
      "HR worker name:\n",
      "Has FTIR\n",
      "Has FTIR?\n",
      "Have you ever accessed a health service for your alcohol or drug use?\n",
      "Have you ever had... X? When was the last time you had... X? [2C-B]\n",
      "Have you ever had... X? When was the last time you had... X? [Amphetamine]\n",
      "Have you ever had... X? When was the last time you had... X? [An unknown powder]\n",
      "Have you ever had... X? When was the last time you had... X? [Cannabis]\n",
      "Have you ever had... X? When was the last time you had... X? [Cocaine]\n",
      "Have you ever had... X? When was the last time you had... X? [Codeine]\n",
      "Have you ever had... X? When was the last time you had... X? [Ecstasy Pills]\n",
      "Have you ever had... X? When was the last time you had... X? [Heroin or other opioids]\n",
      "Have you ever had... X? When was the last time you had... X? [Ketamine]\n",
      "Have you ever had... X? When was the last time you had... X? [LSD]\n",
      "Have you ever had... X? When was the last time you had... X? [MDMA Crystal]\n",
      "Have you ever had... X? When was the last time you had... X? [Magic Mushrooms]\n",
      "Have you ever had... X? When was the last time you had... X? [Mephedrone]\n",
      "Have you ever had... X? When was the last time you had... X? [Nitrous (NOS, laughing gas)]\n",
      "Have you ever had... X? When was the last time you had... X? [Synthetic Cannabinoids]\n",
      "Have you ever had... X? When was the last time you had... X? [Tramadol]\n",
      "Have you ever had... X? When was the last time you had... X? [Valium or other benzodiazepines]\n",
      "Have you ever had... X? When was the last time you had... X? [Xanax]\n",
      "Have you ever taken any other drugs I didn't mention?\n",
      "Have you had any alcohol to drink today?\n",
      "Have you had any other legal or illegal drugs today?\n",
      "Have you or a close friend had a bad experience with this batch?\n",
      "Hit Confidence\n",
      "Hit Confidence.1\n",
      "Hit Confidence.2\n",
      "Hit Confidence.3\n",
      "How many are present?\n",
      "How many times have you used this service:\n",
      "In general terms, who did you get the substance from?\n",
      "Index in FOH sheet\n",
      "Index in FTIR sheet\n",
      "Is a breakline present?\n",
      "Is anything detected after subtraction analysis?\n",
      "Logo\n",
      "MDMA / tablet (mg)\n",
      "MDMA in wash mass\n",
      "MDMA in wash mass (mg)\n",
      "Mass lost (mg)\n",
      "Might have photo\n",
      "NOTES\n",
      "Name and Surname Initial\n",
      "Name of file\n",
      "Next action(s)\n",
      "Note for harm reduction worker\n",
      "Notes\n",
      "Number of people present\n",
      "Paper (mg)\n",
      "Paper + wash mass (mg)\n",
      "Photo Filename\n",
      "Photo filename\n",
      "Photo filename (valueonly)\n",
      "Result going to service user?\n",
      "SampleForm\n",
      "SampleForm_x\n",
      "SampleForm_y\n",
      "SampleNumber\n",
      "SampleSource\n",
      "Send to HR team\n",
      "SoldAs\n",
      "SoldAs_x\n",
      "SoldAs_y\n",
      "Substance detected\n",
      "Substance detected (subtraction)\n",
      "Substance detected.1\n",
      "Substance(s) detected\n",
      "Suggested Filename\n",
      "Tested by\n",
      "Tester\n",
      "Tester_x\n",
      "Tester_y\n",
      "The service user abandoned the intervention before completion.\n",
      "Timestamp\n",
      "Timestamp_x\n",
      "Timestamp_y\n",
      "UID\n",
      "Unusual appearance\n",
      "UserSuspicion_x\n",
      "UserSuspicion_y\n",
      "Was catalogued\n",
      "Was the sample bought, given or found?\n",
      "Wash mass\n",
      "What colour is the pill?\n",
      "What is the logo?\n",
      "What is the mass of one pill? (mg)\n",
      "What is the mass? (mg)\n",
      "What is the quality of the press\n",
      "What is the shape of the pill?\n",
      "What other actions will you do? (tick all that apply)\n",
      "What tone does the colour have\n",
      "What was your FIRST sample number at this event? Did you take a photo or keep the ticket?\n",
      "What was your first sample number at this event? Did you take a photo or keep the ticket?\n",
      "When did you first use this batch?\n",
      "When was the last time you used this service?\n",
      "Where did you obtain this substance from?\n",
      "Which device was a photo taken with? Who does it belong to?\n",
      "Whole pill (mg)\n",
      "Why did you bring this substance to be tested?\n"
     ]
    }
   ],
   "source": [
    "drugs = set()\n",
    "for festival, dfs in data.items():\n",
    "    columns.update(dfs.combined.columns.values)\n",
    "for c in sorted(columns):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "'1 alpha alpha alpha trifluoro m tolyl piperazine'\n",
      "'1 pill 2 powder'\n",
      "'1plsd - years ago'\n",
      "'2 5 i, 4acod, nmdmt'\n",
      "'2-cb'\n",
      "'2-ce'\n",
      "'25-i 2yrs ago, salvia 2yrs,'\n",
      "'25-me0 - few years mxe - 2 years ago'\n",
      "'250mg mdma'\n",
      "'250mg white mitsubushi'\n",
      "'25b _ 2 years'\n",
      "'25i'\n",
      "'25i 3 year'\n",
      "'25i-nbombe, 4 aco dmt, n,n-dmt'\n",
      "'25i-nbome'\n",
      "'25i-nbome, changa, dmt'\n",
      "'2c-b'\n",
      "'2c-b (or 2c-b derivative such as 2ci)'\n",
      "'2c-b-fly'\n",
      "'2c-e'\n",
      "'2c/b'\n",
      "'2cb'\n",
      "'2cb pill'\n",
      "'2ce,'\n",
      "'2ci'\n",
      "'2ci, 25i'\n",
      "'2ci, nicotine'\n",
      "'3-meo-pcp'\n",
      "'3-methylcyclohexanol'\n",
      "'3meo pcp'\n",
      "'3mmt'\n",
      "'4 aco dmt - last year'\n",
      "'4 aco dmt, 2ce, 2ci,'\n",
      "'4-aco-dmt'\n",
      "'4-chloroethcathinone'\n",
      "'4-ho-met,'\n",
      "'4aco dmt'\n",
      "'4fa'\n",
      "'4ho-met (synthesised psilocybin), dmt, 2ci, salvia, mxe'\n",
      "'4meo - 3 years'\n",
      "'5-meo-mipt'\n",
      "'6-apb'\n",
      "'?4mm'\n",
      "'a pill'\n",
      "'a0256'\n",
      "'acid'\n",
      "'acne medication'\n",
      "'aderol'\n",
      "'al-lad'\n",
      "'alcohol'\n",
      "'alcohol nicotine'\n",
      "'alcohol,  5-meo-mipt (moxy)'\n",
      "'alcohol, bromo-dragonfly,'\n",
      "'alcohol, nicotine'\n",
      "'alcohol, nicotine,'\n",
      "'alcohol, nicotine, poppers'\n",
      "'ald-52'\n",
      "'all tests negative, tests are unable to detect valium - speak to lab staff for more info'\n",
      "'amphetamine'\n",
      "'amphetamine (gj note - says it was found)'\n",
      "'amphetamine (speed)'\n",
      "'amphetamine + caffeine'\n",
      "'amphetamine with caffeine'\n",
      "'amphetamine/caffeine'\n",
      "'amt'\n",
      "'amt over a year ago,'\n",
      "'amt, salvia divinorum,'\n",
      "'amyl nitrate - 4 years'\n",
      "'anti-depressant (ssri)'\n",
      "'asborbic acid (vitamin c)'\n",
      "'ascorbic acid (vitamin c)'\n",
      "'ascorbic acid ketamine'\n",
      "'assuming bullshit'\n",
      "'bag that was found'\n",
      "'baking powder'\n",
      "'baking power'\n",
      "'baking soda (sodium bicarbonate)'\n",
      "'benzo fury'\n",
      "'benzocaine'\n",
      "'benzofury, nicotine, alcohol'\n",
      "'binder'\n",
      "'bitcoin blue'\n",
      "'bk-dmbdb pls come talk to lab'\n",
      "'blue punisher'\n",
      "'bought asmdma pill thought looked wrong'\n",
      "'brown powder'\n",
      "'bugatti'\n",
      "'bzp,'\n",
      "'caffeine'\n",
      "'caffeine (suspected amphetamine)'\n",
      "'caffeine and cocaine'\n",
      "'caffeine ketamine'\n",
      "'caffeine only, no speed'\n",
      "'caffeine with mdma'\n",
      "'caffeine, mdma'\n",
      "'caffeine, reagent testing'\n",
      "'caffeine-ampethamine'\n",
      "'caffeine-mdma mix'\n",
      "'cathinone (n-ethylamino-hexanophenone)'\n",
      "'chalk'\n",
      "'changa last year'\n",
      "'changa, 25-i'\n",
      "'chloroquine'\n",
      "'chloroquine confirm with reagent test'\n",
      "'choroquine'\n",
      "'coacaine'\n",
      "'coc'\n",
      "'cocaime'\n",
      "'cocain'\n",
      "'cocaine'\n",
      "'cocaine and ketamine'\n",
      "'cocaine low strength'\n",
      "'cocaine with levamisole impurities'\n",
      "'cocaine/benzocaine'\n",
      "'cociane'\n",
      "'cocodamol'\n",
      "'coke'\n",
      "'coke - strong'\n",
      "'coke cut with speed'\n",
      "'coke suspected'\n",
      "'crack - 2 months'\n",
      "'crack cocaine,'\n",
      "'crck'\n",
      "'creatine'\n",
      "'creatine (nutritional supplement)'\n",
      "'creatine and benzocaine'\n",
      "'crystal meth'\n",
      "'crystal meth - 9 years ago'\n",
      "'diazepam'\n",
      "'dimethlytriptamine'\n",
      "'dk'\n",
      "'dmt'\n",
      "'dmt - 12 months, salvia 12 months, pzp - 12 months'\n",
      "'dmt - 2 years ethylphenidate - over year'\n",
      "'dmt - 4modmt 2 years  ago'\n",
      "'dmt - last year'\n",
      "'dmt - year ago'\n",
      "'dmt - yesterday'\n",
      "'dmt / years microdots years'\n",
      "'dmt 3months ago'\n",
      "'dmt 4 years'\n",
      "'dmt and changa / last year, poppers 2 months ago,'\n",
      "'dmt few years 25i mdoe few years dob few years 5apb few years'\n",
      "'dmt,'\n",
      "'dmt, methamphetamine'\n",
      "'dmt, modafinil peyote tca'\n",
      "'dmt, nicotine'\n",
      "'dmt, nicotine,'\n",
      "'dmt, salvia'\n",
      "'dmt, san pedro'\n",
      "'dmt,ayahuasca'\n",
      "'dmx 2 years ago'\n",
      "'don't know'\n",
      "'don'tknow'\n",
      "'donald trump pill'\n",
      "'dont know - found'\n",
      "'e'\n",
      "'ecstacy'\n",
      "'ecstacy pill'\n",
      "'ecstacy pill transformer'\n",
      "'ecstasy'\n",
      "'ecstasy (mdma)'\n",
      "'ecstasy -mdma'\n",
      "'ecstasy pill'\n",
      "'ecstasy pill (mdma)'\n",
      "'ecstasy pill - 90's / dinosaur'\n",
      "'ecstasy pill orange tesla'\n",
      "'ecstasy pill with mdma'\n",
      "'ecstasy tablet'\n",
      "'ectasy'\n",
      "'ectasy pill'\n",
      "'ecty'\n",
      "'escasy'\n",
      "'escasy tablet'\n",
      "'esctacy partial pill fanta'\n",
      "'estasy'\n",
      "'ethylone'\n",
      "'ethylphenidate'\n",
      "'extasy pill'\n",
      "'f0074'\n",
      "'f0161'\n",
      "'f0177'\n",
      "'f0540'\n",
      "'f1453'\n",
      "'fifa pill'\n",
      "'filler'\n",
      "'flour + turmeric'\n",
      "'found'\n",
      "'found (mdma suspicion)'\n",
      "'found - but suspected mdma based on smell'\n",
      "'found bag'\n",
      "'found it'\n",
      "'found it - no idea'\n",
      "'found it on site'\n",
      "'found it. thought it was cocaine'\n",
      "'found it. unknown'\n",
      "'found on beach'\n",
      "'found on floor'\n",
      "'found on the floor'\n",
      "'found pill'\n",
      "'found pills looked them up either mdma or tramadol'\n",
      "'found powder'\n",
      "'found substance'\n",
      "'found them'\n",
      "'found unknown'\n",
      "'found, think its ketamine'\n",
      "'full pill green heniken'\n",
      "'full pill lv'\n",
      "'full pill mdma'\n",
      "'full pill pink redbull'\n",
      "'full pill pink transformer'\n",
      "'full pill yellow lego man'\n",
      "'ghb'\n",
      "'ghb 2mionths'\n",
      "'ghb, ritaline'\n",
      "'green crack 3 years ago'\n",
      "'green heneken pill'\n",
      "'green tesla full pill'\n",
      "'hash'\n",
      "'hash;'\n",
      "'ice'\n",
      "'inconclusive'\n",
      "'inconclusive - sent for reagent test'\n",
      "'ioaska'\n",
      "'irgacure 907'\n",
      "'k'\n",
      "'karina n'\n",
      "'ket'\n",
      "'ketaine'\n",
      "'ketamin'\n",
      "'ketamine'\n",
      "'ketamine + creatine'\n",
      "'ketamine + msg'\n",
      "'ketamine and cocaine'\n",
      "'ketamine and mdma'\n",
      "'ketamine and msg'\n",
      "'ketamine cocaine'\n",
      "'ketamine cut with vitamin c'\n",
      "'ketamine or cocaine'\n",
      "'ketamine or coke'\n",
      "'ketamine with adulterant'\n",
      "'ketamine with msg'\n",
      "'ketamine, possibly cut with taurine'\n",
      "'ketamine/creatine'\n",
      "'ketamne'\n",
      "'ketaqmine'\n",
      "'ketemin'\n",
      "'ketmain'\n",
      "'ketmaine'\n",
      "'ketmine'\n",
      "'ketsmine'\n",
      "'lactose'\n",
      "'lots'\n",
      "'lsa'\n",
      "'lsa 1year ago'\n",
      "'lsd'\n",
      "'lsd - blotter'\n",
      "'lsd blotter'\n",
      "'lsd tab'\n",
      "'m power'\n",
      "'m&m pill'\n",
      "'matazipine - year ago'\n",
      "'mbm4'\n",
      "'mbone'\n",
      "'mda'\n",
      "'mda, 4-aco-dmt, dmt, maoi,'\n",
      "'mda;'\n",
      "'mdma'\n",
      "'mdma  pill'\n",
      "'mdma & ketamine'\n",
      "'mdma (pill)'\n",
      "'mdma (pills)'\n",
      "'mdma (powder)'\n",
      "'mdma (stone island) pill'\n",
      "'mdma + caffeine'\n",
      "'mdma + ketamine'\n",
      "'mdma + other stimulants'\n",
      "'mdma - pill'\n",
      "'mdma - pill powder'\n",
      "'mdma 210mg'\n",
      "'mdma cristal'\n",
      "'mdma crysral'\n",
      "'mdma crystal'\n",
      "'mdma crystal/ powder'\n",
      "'mdma crystals'\n",
      "'mdma crystsl'\n",
      "'mdma crytal'\n",
      "'mdma or viagra'\n",
      "'mdma partial pill'\n",
      "'mdma pil'\n",
      "'mdma pill'\n",
      "'mdma pill 'louis vuitton''\n",
      "'mdma pill - bitcoin'\n",
      "'mdma pill - blue emoji'\n",
      "'mdma pill - ea sports'\n",
      "'mdma pill - ea7'\n",
      "'mdma pill - green dice'\n",
      "'mdma pill - green emoji'\n",
      "'mdma pill - green premier league'\n",
      "'mdma pill - manchester united'\n",
      "'mdma pill - octagan'\n",
      "'mdma pill - purple tomorrowland'\n",
      "'mdma pill - rolls royce'\n",
      "'mdma pill - silver bar'\n",
      "'mdma pill - unknown brand red pill'\n",
      "'mdma pill -sound cloud pill'\n",
      "'mdma pill / partial sample'\n",
      "'mdma pill crumbles'\n",
      "'mdma pills'\n",
      "'mdma powder'\n",
      "'mdma powder/ crystal'\n",
      "'mdma powder/crystal'\n",
      "'mdma power'\n",
      "'mdma precursor'\n",
      "'mdma tablet'\n",
      "'mdma tomorrowland pill'\n",
      "'mdma transformer pill'\n",
      "'mdma wait for reagent test'\n",
      "'mdma with benzocaine'\n",
      "'mdma with minor caffeine impurities'\n",
      "'mdma with possible crushed up pill in bag'\n",
      "'mdma+mda'\n",
      "'mdma, benzocaine'\n",
      "'mdma, possibly other substances within'\n",
      "'mdma- pill'\n",
      "'mdma/mix'\n",
      "'mdmda'\n",
      "'medafonil'\n",
      "'mephedrone'\n",
      "'mescaline  25i nbome (psyc)'\n",
      "'mescaline analogue.'\n",
      "'mescaline, dmt, 4-aco-dmt, nicotine, alcohol, mxe'\n",
      "'mescaline, dxm, methoxetamine, mdpv'\n",
      "'mescaline, mxe'\n",
      "'meth'\n",
      "'methadrone'\n",
      "'methamphetamine - one year, ghb - year ago'\n",
      "'methanphenodate'\n",
      "'methedrone'\n",
      "'methylene_ioxymeth@mphet@mine'\n",
      "'methylone'\n",
      "'mex 1yr ago'\n",
      "'mexedrone'\n",
      "'mexy'\n",
      "'microcrystaline cellulose'\n",
      "'mm'\n",
      "'mm crytl'\n",
      "'mm pill'\n",
      "'modafinal'\n",
      "'modafinil'\n",
      "'modafinl - yesterday, changa years ago'\n",
      "'modifinal and ritilin, within the last year'\n",
      "'monclair pill'\n",
      "'monfnil, nicotine'\n",
      "'monosodium glutamate'\n",
      "'monosodium glutamate (msg - food additive)'\n",
      "'monosodium glutamate (msg)'\n",
      "'morphine'\n",
      "'msg'\n",
      "'mt  mxe'\n",
      "'mushrooms gel'\n",
      "'mxe'\n",
      "'mxe  meo5-dalt'\n",
      "'mxe, synthetic psilocybin'\n",
      "'n-ethyl pentalone'\n",
      "'n-ethyl pentylone'\n",
      "'n-ethyl-pentylone'\n",
      "'n-ethylpentalone'\n",
      "'n-ethylpentylone'\n",
      "'n/a'\n",
      "'na - rt'\n",
      "'nbome'\n",
      "'nbome,'\n",
      "'nicotine'\n",
      "'nicotine alcohol'\n",
      "'nicotine alcohol, poppers'\n",
      "'nicotine,'\n",
      "'nicotine, alcohol'\n",
      "'nicotine, alcohol,'\n",
      "'nicotine, alcohol, lsa, mondafanil, ritalin,'\n",
      "'nicotine, alcohol, poppers,'\n",
      "'nicotine, poppers,'\n",
      "'nil'\n",
      "'nitrazepam'\n",
      "'no'\n",
      "'no active component'\n",
      "'no active component identified'\n",
      "'no active component via ir'\n",
      "'no active compound - reagent test'\n",
      "'no active compounds'\n",
      "'no active ingredient'\n",
      "'no active substance'\n",
      "'no active substance detected (is plaster of paris)'\n",
      "'no active substance identified'\n",
      "'no active substances - reagent test'\n",
      "'no compound detected'\n",
      "'no compound detected yet'\n",
      "'no compound in our database'\n",
      "'no drug substance detected (plaster of paris)'\n",
      "'no match'\n",
      "'no substance detected'\n",
      "'none'\n",
      "'none - might be alprazolam'\n",
      "'none, suspected zanax'\n",
      "'not known'\n",
      "'not known - found it'\n",
      "'nothing'\n",
      "'nothing - reagent test'\n",
      "'nothing by ir'\n",
      "'paracetamol'\n",
      "'paracetemol'\n",
      "'parcial pill'\n",
      "'part pill pink red bull'\n",
      "'partial mdma pill'\n",
      "'partial pill'\n",
      "'partial pill (blue punisher)'\n",
      "'partial pill ?'\n",
      "'partial pill dr. who'\n",
      "'partial pill found it'\n",
      "'partial pill ghost buster'\n",
      "'partial pill gold bar'\n",
      "'partial pill green turtle'\n",
      "'partial pill roll's royce'\n",
      "'pentylone'\n",
      "'phenibut'\n",
      "'pigment earth'\n",
      "'pill'\n",
      "'pill - mdma'\n",
      "'pill - pece & love'\n",
      "'pill binder'\n",
      "'pill chubachub'\n",
      "'pill duracell'\n",
      "'pill e / mdma'\n",
      "'pill mdma'\n",
      "'pill neon green barcelona football club'\n",
      "'pill square green'\n",
      "'pill superman'\n",
      "'pill/mdma'\n",
      "'plaster of paris'\n",
      "'plaster of paris (concrete)'\n",
      "'plaster of paris and chalk'\n",
      "'plaster of paris(chalk)'\n",
      "'plater of paris'\n",
      "'pma'\n",
      "'pod'\n",
      "'popper (solvent)'\n",
      "'poppers'\n",
      "'poppers - yesterday'\n",
      "'potentially mdma binder'\n",
      "'pregabalin - few days dmt - few months salvia - few months morning glory - 2 months qutiapine few months - zolof - few months'\n",
      "'pregabalin / one month'\n",
      "'procaine'\n",
      "'progaerin'\n",
      "'propylene glycol'\n",
      "'pseudoepedrine'\n",
      "'psilocybin bomb'\n",
      "'psychoactive substances from internet'\n",
      "'punisher pill'\n",
      "'pyridoxine b6 dietyary supplement'\n",
      "'qualudes'\n",
      "'quinine'\n",
      "'quluu, 2c-x, 25-i nbome, pme'\n",
      "'recreationally used anti-depressants and anti-psychotics'\n",
      "'red mdma pill'\n",
      "'ritalin'\n",
      "'ritalin, modafinil'\n",
      "'salvia'\n",
      "'salvia (smoked), benzo furies (legal high pills)'\n",
      "'salvia years ago poppers yesterday's'\n",
      "'salvia,'\n",
      "'salvia, dmt'\n",
      "'san pedro,  ayahuasca'\n",
      "'service user completed survey with sample 953 but screen didn't load without this survey'\n",
      "'service user thought ket as submitted for a friend but friend knew it was mdma'\n",
      "'silver bar'\n",
      "'sold as mdma'\n",
      "'solvants, craytom, ritalin, madafinil'\n",
      "'sorbitol'\n",
      "'speed'\n",
      "'steroids'\n",
      "'sucrose'\n",
      "'sugar'\n",
      "'sugar (tang fruit squash mix)'\n",
      "'synthetic lsd (type unknown)'\n",
      "'synthetic mushrooms'\n",
      "'synthetic thc liquid'\n",
      "'tab of lsd - unknown strength'\n",
      "'tesla, ace of spades mdma pill'\n",
      "'tfmpp (piperazine)'\n",
      "'thc in vape liquid'\n",
      "'thc-a'\n",
      "'the punisher mdma'\n",
      "'truffle'\n",
      "'truffles'\n",
      "'truffles, nicotine, alcohol'\n",
      "'truffles, nicotine, mda, crack cocaine,'\n",
      "'uknown'\n",
      "'unknoen'\n",
      "'unknown'\n",
      "'unknown - found'\n",
      "'unknown - reagent test'\n",
      "'unknown cathnone (irgacure)'\n",
      "'unknown from ir test'\n",
      "'unknown pill'\n",
      "'unknown powder - found on floor maybe cocaine'\n",
      "'unknown sold as cocaine'\n",
      "'unknown substance'\n",
      "'unkown'\n",
      "'unsure'\n",
      "'unsure (found substance)'\n",
      "'valium'\n",
      "'very high strength'\n",
      "'vitamin b6'\n",
      "'vitamin c'\n",
      "'white powder'\n",
      "'xanac'\n",
      "'xanax'\n",
      "'xtc'\n",
      "'xtc crytl'\n",
      "'xtc power'\n",
      "'yellow ace - partial pill'\n",
      "'yes'\n"
     ]
    }
   ],
   "source": [
    "# Get list of already known drugs\n",
    "# all_known = set()\n",
    "# all_known.update(*drugs_map.values())\n",
    "\n",
    "user_drug_columns = [\"Have you ever taken any other drugs I didn't mention?\", 'SoldAs', 'UserSuspicion', 'Substance(s) detected']\n",
    "\n",
    "tester_drug_columns = ['Compound detected', 'Compound detected (Subtraction)', 'Substance detected',\n",
    "                'Substance detected (subtraction)', 'Substance detected.1' ]\n",
    "\n",
    "\n",
    "\n",
    "# prefixes = ['catalog_', 'ftir_', 'mla_', 'hr_']\n",
    "# all_drug_columns = []\n",
    "# for d in drug_columns:\n",
    "#     for p in prefixes:\n",
    "#         all_drug_columns.append(p+d)\n",
    "\n",
    "drug_names = set()\n",
    "for festival, dfs in data.items():\n",
    "    df = dfs.combined\n",
    "    for cname in user_drug_columns:\n",
    "        if cname in df.columns.values:\n",
    "            drug_names.update(df[cname].str.lower().unique())\n",
    "if np.nan in drug_names:\n",
    "    drug_names.remove(np.nan)\n",
    "if None in drug_names:\n",
    "    drug_names.remove(None)\n",
    "drug_names = set([s.strip() for s in drug_names])\n",
    "\n",
    "for d in sorted(drug_names):\n",
    "    print(\"'%s'\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleNumber',\n",
       " 'catalog_SampleSource',\n",
       " 'catalog_SampleForm',\n",
       " 'ftir_SampleForm',\n",
       " 'mla_SampleForm',\n",
       " 'hr_What was your first sample number at this event? Did you take a photo or keep the ticket?',\n",
       " 'hr_Was the sample bought, given or found?']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we overwrite the values - if necessary we could create separate columns\n",
    "# Create dict for replace function is form {column : {value_to_replace, replacement_value}}\n",
    "replace_d = {}\n",
    "drug_columns = ['sold/acquired/advertised as', 'Client suspicion', 'Final Result', 'SubmittedSubstanceAs', 'other_specify']\n",
    "\n",
    "# Firstly convert all columns to lower case and remove any spaces\n",
    "def clean(value):\n",
    "    if type(value) is str:\n",
    "        value = value.strip().lower()\n",
    "    return value\n",
    "\n",
    "for column in drug_columns:\n",
    "    df_final[column] = df_final[column].map(clean, na_action='ignore')\n",
    "\n",
    "for column in drug_columns:\n",
    "    replace_d[column] = {}\n",
    "    for drug, names in drugs_map.items():\n",
    "        for name in names:\n",
    "            replace_d[column][name] = drug\n",
    "\n",
    "# Replace values\n",
    "df_final.replace(replace_d, inplace=True)\n",
    "            \n",
    "# NO_ANALYSIS as is treated separtely as only applies to Final Result - also can't include with other dict\n",
    "# or the replacement values and keys overlap\n",
    "NO_ANALYSIS = 'analysis_inconclusive'\n",
    "no_analysis = ['compound not in library', 'inconclusive', 'insufficient quantity for testing', \n",
    "               'insufficient sample', 'insufficient sample', 'lost', 'no active component identified', \n",
    "               'no match', 'no match', 'none', 'nothing detected', 'result missing', 'unable to test', 'unknown']\n",
    "\n",
    "# Fix 'Final Result' for NO_ANALYSIS\n",
    "column = 'Final Result'\n",
    "replace_d = {column: {}}\n",
    "for name in no_analysis:\n",
    "    replace_d[column][name] = NO_ANALYSIS\n",
    "\n",
    "# Replace values\n",
    "df_final.replace(replace_d, inplace=True)\n",
    "\n",
    "# Additional grouping requested by Fiona\n",
    "column = 'sold/acquired/advertised as'\n",
    "replace_d = {column: {'found' : 'unknown',\n",
    "                      \"don't know\" : 'unknown',\n",
    "                      'not sure' : 'unknown',\n",
    "                     }}\n",
    "df_final.replace(replace_d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 43 duplicated ftir SampleNumbers ['F0071', 'F0247', 'F0206', 'F0367', 'F0019', 'F0546', 'F0446', 'F0005', 'F0659', 'F1137', 'F0983', 'F0938', 'F0869', 'F0838', 'F0981', 'F0865', 'F0668', 'F0816', 'F0878', 'F0885', 'F0833', 'F0815', 'F1196', 'F1253', 'F1313', 'F1393', 'F1215', 'F1392', 'F1640', 'F1172', 'F1606', 'F1433', 'F1431', 'F1609', 'F1660', 'F1623', 'F1792', 'F0912', 'F1876', 'F1830', 'F1262', 'F1439', 'F1904'] ###\n",
      "### 1 duplicated hr SampleNumbers ['F9999'] ###\n"
     ]
    }
   ],
   "source": [
    "# The code above runs across all festival data. The code below is for looking at the data for an individual\n",
    "# festival (and so really should be in a function), but for the time being we just set the variables we\n",
    "# require here\n",
    "dfs = data['boomtown']\n",
    "duplicates = Duplicates(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate FTIR SampleNumber B0103 (line: 28) DIFFERENT Catalog sample (line: 36)\n",
      "['Found or otherwise not known', '', 'powder'] 2018-08-25 15:56:29\n",
      "['Found or otherwise not known', 'No', 'powder'] 2018-08-25 15:02:33\n",
      "Duplicate FTIR SampleNumber B0103 (line: 29) DIFFERENT Catalog sample (line: 36)\n",
      "['Found or otherwise not known', '', 'pill'] 2018-08-25 15:58:35\n",
      "['Found or otherwise not known', 'No', 'powder'] 2018-08-25 15:02:33\n",
      "Duplicate FTIR SampleNumber B0131 (line: 50) MATCHES Catalog sample (line: 55)\n",
      "Duplicate FTIR SampleNumber B0131 (line: 51) MATCHES Catalog sample (line: 55)\n",
      "Duplicate FTIR SampleNumber B0221 (line: 136) DIFFERENT Catalog sample (line: 132)\n",
      "['Found or otherwise not known', 'No', 'powder'] 2018-08-26 15:42:33\n",
      "['', '', 'powder'] 2018-08-26 15:30:58\n",
      "Duplicate FTIR SampleNumber B0221 (line: 137) DIFFERENT Catalog sample (line: 132)\n",
      "['Found or otherwise not known', 'No', 'powder'] 2018-08-26 15:58:20\n",
      "['', '', 'powder'] 2018-08-26 15:30:58\n",
      "Duplicate FTIR SampleNumber B0229 (line: 145) DIFFERENT Catalog sample (line: 140)\n",
      "['Found or otherwise not known', 'No', 'powder'] 2018-08-26 15:56:23\n",
      "['', '', 'powder'] 2018-08-26 15:48:00\n",
      "Duplicate FTIR SampleNumber B0229 (line: 146) DIFFERENT Catalog sample (line: 140)\n",
      "['Found or otherwise not known', 'No', 'pill'] 2018-08-26 16:31:40\n",
      "['', '', 'powder'] 2018-08-26 15:48:00\n"
     ]
    }
   ],
   "source": [
    "def find_duplicate_matches(duplicates, df1, df2, df1_name='DataFrame1', df2_name='DataFrame2'):\n",
    "    hr = False\n",
    "    if df1_name.lower()[:2] == 'hr':\n",
    "        hr = True\n",
    "    duplicate_matches = {}\n",
    "    min_stage_delay = 60 * 1\n",
    "    max_stage_delay = 60 * 60\n",
    "    for sample_number in duplicates:\n",
    "        duplicate_matches[sample_number] = {}\n",
    "        for df1_idx, df1_row in df1.loc[df1['SampleNumber'] == sample_number].iterrows():\n",
    "            for df2_idx, df2_row in df2.loc[df2['SampleNumber'] == sample_number].iterrows():\n",
    "                df1_data = df1_row.loc[['SoldAs', 'AlreadyTried']].values.tolist()\n",
    "                if not hr:\n",
    "                    df1_data.append(df1_row.SampleForm)\n",
    "                df1_time = df1_row.Timestamp\n",
    "                df2_data = df2_row.loc[['SoldAs', 'AlreadyTried']].values.tolist()\n",
    "                if not hr:\n",
    "                    df2_data.append(df2_row.SampleForm)\n",
    "                df2_time = df2_row.Timestamp\n",
    "                if df2_time >= df1_time:\n",
    "                    delta_t = (df2_time - df1_time).seconds\n",
    "                else:\n",
    "                    delta_t = (df1_time - df2_time).seconds\n",
    "                if df1_data == df2_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                    print(\"Duplicate %s SampleNumber %s (line: %d) MATCHES %s sample (line: %d)\" % \\\n",
    "                          (df1_name, sample_number, df1_idx + 1, df2_name, df2_idx + 1))\n",
    "                    duplicate_matches[sample_number][df1_idx] = True\n",
    "                else:\n",
    "                    print(\"Duplicate %s SampleNumber %s (line: %d) DIFFERENT %s sample (line: %d)\\n%s %s\\n%s %s\" % \\\n",
    "                          (df1_name, sample_number, df1_idx + 1, df2_name, df2_idx + 1,\n",
    "                           df1_data, df1_time,\n",
    "                           df2_data, df2_time))\n",
    "                    duplicate_matches[sample_number][df1_idx] = False\n",
    "    return duplicate_matches\n",
    "\n",
    "def match_orphans_to_duplicates(df1_orphans, duplicate_matches, df1, df2):\n",
    "    for orphan_sample_number in df1_orphans:\n",
    "        df1_data = df1.loc[df1['SampleNumber'] == orphan_sample_number, ['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']]\n",
    "        df1_data = df1_data.values.tolist()[0]\n",
    "        df1_time = df1_data.pop()\n",
    "        for sample_number, indexd in duplicate_matches.items():\n",
    "            for k, v in indexd.items():\n",
    "                if not v:\n",
    "                    df2_data = dfs.catalog.iloc[k][['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']].values.tolist()\n",
    "                    df2_time = df2_data.pop()\n",
    "                    if df2_time >= df1_time:\n",
    "                        delta_t = (df2_time - df1_time).seconds\n",
    "                    else:\n",
    "                        delta_t = (df1_time - df2_time).seconds\n",
    "                    if df2_data == df1_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                        print(\"Orphan {} could be match for duplicate {} (line: {})\\n{} {}\\n{} {}\".format(orphan_sample_number,\n",
    "                                                                                                  sample_number, k+1,\n",
    "                                                                                                  df2_data, df2_time,\n",
    "                                                                                                  df1_data, df1_time))\n",
    "\n",
    "\n",
    "#duplicate_matches = find_duplicate_matches(duplicates.catalog, dfs.catalog, dfs.ftir, df1_name='Catalog', df2_name='FTIR')\n",
    "duplicate_matches = find_duplicate_matches(duplicates.ftir, dfs.ftir, dfs.catalog, df1_name='FTIR', df2_name='Catalog')\n",
    "#duplicate_matches = find_duplicate_matches(duplicates.hr, dfs.hr, dfs.catalog, df1_name='HR', df2_name='Catalog')\n",
    "\n",
    "#match_orphans_to_duplicates(ftir_orphan, duplicate_matches, dfs.ftir, dfs.catalog)\n",
    "# match_orphans_to_duplicates(catalog_orphan, duplicate_matches, dfs.catalog, dfs.ftir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad SampleNumber FXXX\n",
      "Bad SampleNumber FXXX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmht/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/Users/jmht/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "# Check orphans against the FTIR sheet using just their numbers\n",
    "def match_orphans_with_sample_integer(orphans, orphan_df, ref_df):\n",
    "#     min_stage_delay = 60 * 1\n",
    "#     max_stage_delay = 60 * 60\n",
    "    def to_int(sn):\n",
    "        if type(sn) is str:\n",
    "            try:\n",
    "                sn = int(sn[-4:])\n",
    "            except ValueError:\n",
    "                print(\"Bad SampleNumber %s\" % sn)\n",
    "                sn = np.nan\n",
    "        return sn\n",
    "    orphan_df['SampleInteger'] = orphan_df['SampleNumber'].apply(to_int)\n",
    "    ref_df['SampleInteger'] = ref_df['SampleNumber'].apply(to_int)\n",
    "    orphan_ints = map(to_int, orphans)\n",
    "    skipform = True\n",
    "    for orphan_sample_number, oint in zip(orphans, orphan_ints):\n",
    "        for orphan_idx, orphan_row in orphan_df.loc[orphan_df['SampleNumber'] == orphan_sample_number].iterrows():\n",
    "            for ref_idx, ref_row in ref_df.loc[ref_df['SampleInteger'] == oint].iterrows():\n",
    "                orphan_data = orphan_row.loc[['SampleForm', 'SoldAs', 'AlreadyTried']].values.tolist()\n",
    "                orphan_time = orphan_row.Timestamp\n",
    "                ref_sample_number = ref_row.SampleNumber\n",
    "                ref_data = ref_row.loc[['SampleForm', 'SoldAs', 'AlreadyTried']].values.tolist()\n",
    "                ref_time = ref_row.Timestamp\n",
    "                delta_t = (ref_time - orphan_time).seconds\n",
    "#                 if orphan_data == ref_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                if skipform:\n",
    "                    orphan_data.pop(0)\n",
    "                    ref_data.pop(0)\n",
    "                if orphan_data == ref_data:\n",
    "                    print(\"HR orphan %s (line: %d) could be match for FTIR SampleNumber %s (line: %d)\\n%s %s\\n%s %s\" % \\\n",
    "                          (orphan_sample_number, orphan_idx + 1, ref_sample_number, ref_idx + 1, orphan_data, orphan_time, ref_data, ref_time))\n",
    "\n",
    "# match_orphans_with_sample_integer(catalog_orphan, dfs.catalog, dfs.ftir)\n",
    "match_orphans_with_sample_integer(hr_orphan, dfs.hr, dfs.catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmht/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Check orphans against other orphans just using data\n",
    "def match_orphans_vs_orphans(orphan1_list, orphan1_df, orphan2_list, orphan2_df, hr=False):\n",
    "    min_stage_delay = 60 * 1\n",
    "    max_stage_delay = 60 * 60\n",
    "    for orphan1 in orphan1_list:\n",
    "        orphan1_row = orphan1_df.loc[orphan1_df['SampleNumber'] == orphan1].iloc[0]\n",
    "        for orphan2 in orphan2_list:\n",
    "            orphan2_row = orphan2_df.loc[orphan2_df['SampleNumber'] == orphan2].iloc[0]\n",
    "            orphan1_data = orphan1_row.loc[['SampleForm', 'SoldAs', 'AlreadyTried']].values.tolist()\n",
    "            orphan1_time = orphan1_row.Timestamp\n",
    "            orphan2_data = orphan2_row.loc[['SampleForm', 'SoldAs', 'AlreadyTried']].values.tolist()\n",
    "            orphan2_time = orphan2_row.Timestamp\n",
    "            delta_t = (orphan2_time - orphan1_time).seconds\n",
    "            if orphan1_data == orphan2_data and min_stage_delay <= delta_t <= max_stage_delay:\n",
    "                print(\"orphan1 %s could be match for orphan2 %s\\n%s %s\\n%s %s\" % \\\n",
    "                      (orphan1, orphan2, orphan1_data, orphan1_time, orphan1_data, orphan1_time))\n",
    "\n",
    "# match_orphans_with_sample_integer(catalog_orphan, dfs.catalog, dfs.ftir)\n",
    "match_orphans_vs_orphans(catalog_orphan, dfs.catalog, ftir_orphan, dfs.ftir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs.catalog[dfs.catalog['SampleNumber'].isin(catalog.duplicates)]\n",
    "#pd.DataFrame({'SampleNumber' : duplicates.ftir}).to_csv('ftir_sn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up catalog\n",
    "# Drop all unwanted columns\n",
    "\n",
    "#  or 'Your initials'\n",
    "l = set(['Your initials',\n",
    "         'Your name and first initial',\n",
    "         'Which device was a photo taken with? Who does it belong to?',\n",
    "         'Is a breakline present?',\n",
    "         'Unusual appearance'\n",
    "        ])\n",
    "\n",
    "to_drop = set(dfs.catalog.columns).intersection(l)\n",
    "dfs.catalog.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "d = {\n",
    "    'Timestamp' : 'Catalog timestamp',\n",
    "    'Sample Advertised/Acquired/Sold As': 'Catalog_SoldAs',\n",
    "    'Sample Form' : 'Catalog_Form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'Catalog_Tried',\n",
    "    'What is the mass? (mg)': 'FullPillMass',\n",
    "    'What is the shape of the pill?': 'PillShape',\n",
    "    'What is the logo?': 'PillLogo',\n",
    "    'What colour is the pill?': 'PillColour'\n",
    "}\n",
    "dfs.catalog.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('COLS ', Index([                                                           u'Timestamp',\n",
      "                                                              u'Sample Number',\n",
      "                                                                     u'Tester',\n",
      "                                                                    u'Sold As',\n",
      "                                                                u'Sample Form',\n",
      "                                                              u'Already Tried',\n",
      "                                                             u'User Suspicion',\n",
      "                                                         u'Substance detected',\n",
      "                                                             u'Hit Confidence',\n",
      "                                                          u'Compound detected',\n",
      "                                                           u'Hit Confidence.1',\n",
      "                                                                 u'Brief Note',\n",
      "                           u'Is anything detected after subtraction analysis?',\n",
      "                                            u'Compound detected (Subtraction)',\n",
      "                                                           u'Hit Confidence.2',\n",
      "                                                       u'Substance detected.1',\n",
      "                                                           u'Hit Confidence.3',\n",
      "                                                               u'Brief Note.1',\n",
      "                                                             u'Next action(s)',\n",
      "                                                      u'Substance(s) detected',\n",
      "                                           u'\"Strength\" of powdered substance',\n",
      "       u'Does the substance detected match the substance that was advertised?',\n",
      "                                             u'Note for harm reduction worker',\n",
      "                                                            u'Send to HR team'],\n",
      "      dtype='object'))\n",
      "('SS ', 1691    N-Ethylpentylone\n",
      "1692    N-Ethylpentylone\n",
      "1694    N-Ethylpentylone\n",
      "1696             Cocaine\n",
      "0                   MDMA\n",
      "Name: Substance detected, dtype: object)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_ftir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f76c2c2a13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_ftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Copy values from 'Compound detected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Brief Note.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ftir' is not defined"
     ]
    }
   ],
   "source": [
    "# For FTIR columns need to merge the data from the 'Compound detected', 'Hit Confidence.1' columns into the\n",
    "# 'Substance detected', 'Hit Confidence' column where the substance detected was 'other'\n",
    "print(\"COLS \",dfs.ftir.columns)\n",
    "print(\"SS \",dfs.ftir['Substance detected'][:5])\n",
    "mask = dfs.ftir['Substance detected'] != 'Other'\n",
    "dfs.ftir['Substance detected'].where(mask, dfs.ftir['Compound detected'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence'].where(mask, dfs.ftir['Hit Confidence.1'], inplace=True)\n",
    "dfs.ftir.drop(['Compound detected', 'Hit Confidence.1', 'Brief Note'], axis=1, inplace=True)\n",
    "\n",
    "mask = dfs.ftir['Compound detected (Subtraction)'] != 'Other'\n",
    "dfs.ftir['Compound detected (Subtraction)'].where(mask, df_ftir['Substance detected.1'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence.2'].where(mask, dfs.ftir['Hit Confidence.3'], inplace=True)\n",
    "dfs.ftir.drop(['Substance detected.1', 'Hit Confidence.3', 'Brief Note.1'], axis=1, inplace=True)\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['Your name and surname initial',\n",
    "     'User Suspicion',\n",
    "     'Is anything detected after subtraction analysis?',\n",
    "     'Analysis required', \n",
    "     'Next action(s)',\n",
    "     'Send to HR team'\n",
    "    ]\n",
    "#'Note for harm reduction worker'\n",
    "to_drop = set(dfs.ftir.columns).intersection(l)\n",
    "dfs.ftir.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'FTIR timestamp',\n",
    "    'Sample Sold As': 'FTIR Sold As',\n",
    "    'Sample Form' : 'FTIR form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'FTIR tried',\n",
    "    'Substance(s) detected' : 'FTIR final result',\n",
    "    'Substance detected' : 'FTIR result1',\n",
    "    'Hit Confidence' :  'FTIR hit1',\n",
    "    'Is anything detected after subtraction analysis?' : 'FTIR subtraction positive',\n",
    "    'Compound detected (Subtraction)' :  'FTIR result2',\n",
    "    'Hit Confidence.2' :  'FTIR hit2',\n",
    "    '\"Strength\" of powdered substance' : 'FTIR Powder Strength',\n",
    "    'Does the substance detected match the substance that was advertised?' : 'FTIR Matches Sold As',\n",
    "}\n",
    "dfs.ftir.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up HR form\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['HR worker name:']\n",
    "dfs.hr.drop(l, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'HR timestamp',\n",
    "    'You submitted a substance for analysis. What were you told it was when you got it?': 'HR Sold as',\n",
    "    'Had you already tried this substance before getting it tested?': 'HR tried',\n",
    "    'What was your first sample number at this event? Did you take a photo or keep the ticket?': 'Previous Sample Number'\n",
    "}\n",
    "dfs.hr.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix column orders\n",
    "prefix = ['Sample Number',\n",
    "          'Catalog timestamp', 'FTIR timestamp', 'HR timestamp',\n",
    "          'Catalog Sold As', 'FTIR Sold As','HR Sold as', \n",
    "          'Catalog form', 'FTIR form',\n",
    "          'Catalog tried', 'FTIR tried', 'HR tried']\n",
    "columns = [c for c in df_all.columns if c not in prefix]\n",
    "columns = prefix + columns\n",
    "df_all = df_all[columns]\n",
    "df_all.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
