{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues with MADE dataset:\n",
    "FTIR\n",
    "* Dodgy sample numbers\n",
    "* 2 Hit confidence columns\n",
    "* 2 substance detected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fix_sample_number(x):\n",
    "    \"\"\"Make sure all samples numbers are of form: AXXX (where A is one of A, F, W and X is a digit)\"\"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return x # leave NaN's alone\n",
    "    if (isinstance(x, str) or isinstance(x, unicode)) and len(x) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        sn = 'F{:04d}'.format(int(x))\n",
    "    except ValueError:\n",
    "        # Assume string so make sure it's of the right format\n",
    "        sn = str(x).strip().capitalize()\n",
    "    if sn[0] not in ['A', 'F', 'W'] or len(sn) != 5:\n",
    "        print(\"!!! Bad ID \\'%s\\'\" % sn)\n",
    "    return sn\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")\n",
    "\n",
    "def enumerate_duplicates(row):\n",
    "    \"\"\"Append a counter to duplicate labels\"\"\"\n",
    "    SEPARATOR = '.'\n",
    "    duplicates = {}\n",
    "    updated_row = []\n",
    "    for r in row:\n",
    "        count = duplicates.get(r, 0)\n",
    "        if count > 0:\n",
    "            label = \"{}{}{}\".format(r, SEPARATOR, count)\n",
    "        else:\n",
    "            label = r\n",
    "        updated_row.append(label)\n",
    "        duplicates[r] = count + 1\n",
    "    return updated_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftir_csv = 'MADE/FTIR Analysis Data Recording Form.csv'\n",
    "catalog_csv = 'MADE/Sample Cataloguing Form.csv'\n",
    "reagent_csv = 'MADE/Reagent Outcomes.csv'\n",
    "hr_csv = 'MADE/MADE MAST Intervention Questionnaire.csv'\n",
    "\n",
    "date_cols = ['Timestamp']\n",
    "df_ftir = pd.read_csv(ftir_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_catalog = pd.read_csv(catalog_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_reagent = pd.read_csv(reagent_csv, engine=\"python\", parse_dates=date_cols)\n",
    "df_hr = pd.read_csv(hr_csv, engine=\"python\", parse_dates=date_cols)\n",
    "\n",
    "mla_excel = 'MADE/MADE - Loop 2018 event results sheet_.xlsx'\n",
    "df_mla = pd.read_excel(mla_excel, sheetname='MLA', header=1)\n",
    "\n",
    "# Sort out column names\n",
    "df_reagent.rename(columns={'Sample Code':'Sample Number', 'Substance(s) detected' : 'Reagent Result'}, inplace=True)\n",
    "df_hr.rename(columns={'Sample Number:':'Sample Number'}, inplace=True)\n",
    "df_mla.rename(columns={'Sample Num':'Sample Number'}, inplace=True)\n",
    "\n",
    "# Make all sample numbers a 4-digit code starting with F\n",
    "df_ftir['Sample Number'] = df_ftir['Sample Number'].apply(fix_sample_number)\n",
    "df_catalog['Sample Number'] = df_catalog['Sample Number'].apply(fix_sample_number)\n",
    "df_reagent['Sample Number'] = df_reagent['Sample Number'].apply(fix_sample_number)\n",
    "df_hr['Sample Number'] = df_hr['Sample Number'].apply(fix_sample_number)\n",
    "df_mla['Sample Number'] = df_mla['Sample Number'].apply(fix_sample_number)\n",
    "\n",
    "# Prune down MLA to valid sample numbers\n",
    "df_mla = df_mla[df_mla['Sample Number'].notnull()]\n",
    "\n",
    "DataFrames = namedtuple('DataFrames', ['catalog', 'ftir', 'reagent','mla', 'hr'])\n",
    "dfs = DataFrames(\n",
    "    catalog=df_catalog,\n",
    "    ftir=df_ftir,\n",
    "    reagent=df_reagent,\n",
    "    mla=df_mla,\n",
    "    hr=df_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING TRUCKFEST\n",
      "GOT ROWS  [[u'Timestamp', u'Sample Number', u'Your name and first initial', u'Sample Source', u'Sample Advertised/Acquired/Sold As', u'Has the Service User or a close friend tried this batch?', u'User Suspicion', u'Sample Form', u'What is the logo?', u'', u'Which device was a photo taken with? Who does it belong to?', u'What is the mass? (mg)', u'What is the shape of the pill?', u'Is a breakline present?', u'Unusual appearance', u'What colour is the pill?', u'Photo Filename'], [u'20/07/2018 16:58:55', u'A0005', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Fanta', u'', u\"Jens's phone\", u'483', u'Circular', u'Yes', u'', u'Orange', u'A0005-TF18 Orange Fanta'], [u'20/07/2018 13:53:21', u'A0007', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Trophy', u'', u'Loop Camera', u'611', u'TROPHY', u'No', u'Fluorescent', u'Orange', u'A0007-TF18 Orange Trophy'], [u'20/07/2018 13:55:14', u'A0008', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Whatsapp Phone Speech Bubble', u'', u'Loop Camera', u'344', u'Cut-out of logo', u'No', u'Fluorescent', u'Green', u'A0008-TF18 Green Whatsapp Phone Speech Bubble'], [u'20/07/2018 13:57:42', u'A0009', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Pharmaceutical', u'V MOG5', u'', u'Loop Camera', u'553', u'Circular', u'Yes', u'', u'White', u'A0009-TF18 White V MOG5'], [u'20/07/2018 13:59:41', u'A0010', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Skype', u'', u'Loop Camera', u'516', u'Cut-out of logo', u'Yes', u'NL LOGO ON BACK', u'WHITE BLUE', u'A0010-TF18 White Blue Skype'], [u'20/07/2018 14:08:50', u'A0011', u'BReed', u'Amnesty', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Heineken', u'', u'Loop Camera', u'376', u'Square/Rectangular', u'Yes', u'Pastel, grainy', u'Green', u'A0011-TF18 Green Heineken'], [u'20/07/2018 14:12:50', u'A0012', u'BReed', u'Amnesty', u'Found or otherwise not known', u'No', u'', u'Pharmaceutical', u'MS', u'', u'Loop Camera', u'196', u'Circular', u'Yes', u'Pastel', u'Blue', u'A0012-TF18 Blue MS'], [u'21/07/2018 15:11:31', u'A0013', u'BReed', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0013-TF18  '], [u'21/07/2018 15:16:12', u'A0014', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Medusa Versace', u'', u'Loop Camera', u'401', u'Circular', u'No', u'Fluorescent', u'Pink', u'A0014-TF18 Pink Medusa Versace'], [u'21/07/2018 15:21:24', u'A0015', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0015-TF18  '], [u'21/07/2018 15:24:22', u'A0016', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Soundcloud', u'', u'Loop Camera', u'320', u'CLOUD', u'Yes', u'Fluorescent', u'Orange', u'A0016-TF18 Orange Soundcloud'], [u'21/07/2018 15:27:25', u'A0017', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Whatsapp Telephone', u'', u'Loop Camera', u'350', u'SPEECH BUBBLE', u'No', u'', u'Green', u'A0017-TF18 Green Whatsapp Telephone'], [u'21/07/2018 15:28:36', u'A0020', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0020-TF18  '], [u'21/07/2018 15:30:04', u'A0018', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0018-TF18  '], [u'21/07/2018 15:31:09', u'A0020', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0020-TF18  '], [u'21/07/2018 15:32:33', u'A0023', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0023-TF18  '], [u'21/07/2018 15:34:47', u'A0025', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0025-TF18  '], [u'21/07/2018 15:35:30', u'A0024', u'', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0024-TF18  '], [u'21/07/2018 15:36:43', u'A0027', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0027-TF18  '], [u'21/07/2018 15:39:23', u'A0021', u'KARINA N ', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Stone Island Compass', u'', u'Loop Camera', u'500', u'Square/Rectangular', u'Yes', u'PASTEL', u'Yellow', u'A0021-TF18 Yellow Stone Island Compass'], [u'21/07/2018 15:39:54', u'A0028', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0028-TF18  '], [u'21/07/2018 15:43:54', u'A0026', u'KARINA N ', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Partial ecstasy pill', u'Hulk', u'', u'Loop Camera', u'820', u'IRREGULAR ', u'Yes', u'Fluorescent', u'Orange', u'A0026-TF18 Orange Hulk'], [u'21/07/2018 15:45:27', u'A0030', u'KARINA N', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Doctor Who/Tardis', u'', u'Loop Camera', u'450', u'Cut-out of logo', u'No', u'', u'Blue', u'A0030-TF18 Blue Doctor Who/Tardis'], [u'21/07/2018 15:47:34', u'A0019', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'100 Emoji', u'', u'Loop Camera', u'440', u'Cut-out of logo', u'No', u'Fluorescent', u'Orange', u'A0019-TF18 Orange 100 Emoji'], [u'21/07/2018 15:49:25', u'A0029', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Red Bull ', u'', u'Loop Camera', u'500', u'Square/Rectangular', u'Yes', u'Fluorescent', u'Pink', u'A0029-TF18 Pink Red Bull'], [u'21/07/2018 15:52:07', u'A0031', u'A0031', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'Xanax 666', u'', u'Loop Camera', u'150', u'Square/Rectangular', u'Yes', u'', u'White', u'A0031-TF18 White Xanax 666'], [u'21/07/2018 15:53:30', u'A0032', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Ecstasy pill', u'M&Ms', u'', u'Loop Camera', u'540', u'Cut-out of logo', u'Yes', u'', u'PINK WHITE', u'A0032-TF18 Pink White M&Ms'], [u'21/07/2018 15:54:28', u'A0033', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0033-TF18  '], [u'21/07/2018 15:55:57', u'A0034', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0034-TF18  '], [u'21/07/2018 15:56:34', u'A0035', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0035-TF18  '], [u'21/07/2018 15:58:08', u'A0036', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0036-TF18  '], [u'21/07/2018 15:58:47', u'A0037', u'ABI A', u'Security/Police direct', u'Found or otherwise not known', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0037-TF18  '], [u'21/07/2018 16:35:48', u'F0038', u'Jens', u'Security/Police direct', u'Crushed paracetamol', u'No', u'', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'F0038-TF18  '], [u'22/07/2018 10:33:55', u'A0039', u'Abi A', u'Welfare', u'Found or otherwise not known', u'Yes', u'From welfare, user was concerned and experienced unexpected effects ', u'Powder/capsule/bomb/crystal', u'', u'', u'', u'', u'', u'', u'', u'', u'A0039-TF18  '], [u'22/07/2018 10:35:39', u'A0040', u'Abi A', u'Welfare', u'MDMA', u'Yes', u'From welfare, user was concerned and experienced unexpected effects ', u'Partial ecstasy pill', u'Hulk ', u'', u'Loop Camera', u'420', u'Cut-out of logo', u'Yes', u'Fluorescent', u'Orange', u'A0040-TF18 Orange Hulk']]\n",
      "Canonicalising catalog\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'df_ftir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-360-e1db02b2f2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;31m# data['ynot'] = get_data(service, YNOT2018_SPREADSHEET_ID)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"PROCESSING TRUCKFEST\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'truckfest'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRUCKFEST2018_SPREADSHEET_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;31m# print \"PROCESSING LSTD\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# data['lstd'] = get_data(service, LSTD2018_SPREADSHEET_ID)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-360-e1db02b2f2a1>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(service, SPREADSHEET_ID)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_ftir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreagent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_reagent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_mla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'df_ftir' is not defined"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = 'raise'\n",
    "\n",
    "# Need to define in main or we can't pickle the data objects\n",
    "class DataFrames(object):\n",
    "    def __init__(self):\n",
    "        catalog = None\n",
    "        ftir = None\n",
    "        reagent = None\n",
    "        mla = None\n",
    "        hr = None\n",
    "\n",
    "def gsheets_service():\n",
    "    from googleapiclient.discovery import build\n",
    "    from httplib2 import Http\n",
    "    from oauth2client import file, client, tools\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    CREDS_FILE = '/opt/random/MADE/JensDataExportJupyter_client_secret.json'\n",
    "    SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "    store = file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        import argparse\n",
    "        flags = argparse.ArgumentParser(parents=[tools.argparser]).parse_args([])\n",
    "        flow = client.flow_from_clientsecrets(CREDS_FILE, SCOPES)\n",
    "        creds = tools.run_flow(flow, store, flags)\n",
    "    service = build('sheets', 'v4', http=creds.authorize(Http()))\n",
    "    return service\n",
    "\n",
    "def get_df(service, SPREADSHEET_ID, SS_RANGE, mla=False):\n",
    "    # Call the Sheets API\n",
    "    result = service.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                                range=SS_RANGE).execute()\n",
    "    values = result.get('values', [])\n",
    "    if not values:\n",
    "        print('*** No data found ***')\n",
    "        return None\n",
    "\n",
    "    # mla has irrelevant stuff in columns 1 and 3 and sample numbers in first column\n",
    "    if mla:\n",
    "        values.pop(0)\n",
    "        values.pop(1)\n",
    "        def not_blank(row):\n",
    "            return len(row[0]) > 0       \n",
    "    else:\n",
    "        def not_blank(row):\n",
    "            return sum(map(len, row[:6])) > 0\n",
    "\n",
    "    rows = filter(not_blank, values)\n",
    "    if not rows:\n",
    "        print('*** No data found after pruning rows! ***')\n",
    "        return None\n",
    "    \n",
    "    columns = enumerate_duplicates(rows[0])\n",
    "    ncols = len(rows[0])\n",
    "    row_max = max(map(len, rows[1:]))\n",
    "    width = min(ncols, row_max)\n",
    "    return pd.DataFrame(rows[1:], columns=columns[:width])\n",
    "\n",
    "def canonicalise_df(df, source=None):\n",
    "    \"\"\"Initial cleaning of all dataframes\"\"\"\n",
    "    #from pandas._libs.tslib import OutOfBoundsDatetime\n",
    "    if source:\n",
    "        print(\"Canonicalising %s\" % source)\n",
    "    # Standardise names\n",
    "    d = {\n",
    "        'Sample Code':'SampleNumber',\n",
    "        'Sample Number:':'SampleNumber',\n",
    "        'Sample Number':'SampleNumber',\n",
    "        'Sample number':'SampleNumber',\n",
    "        'Sample Num':'SampleNumber',\n",
    "        'Sample Number i.e F0XXX' : 'SampleNumber',\n",
    "        \n",
    "        'Sample Advertised/Acquired/Sold As' : 'SoldAs',\n",
    "        'Sample Sold As' : 'SoldAs',\n",
    "        \n",
    "        'Sample Source' :'SampleSource',\n",
    "\n",
    "        'User Suspicion' :'UserSuspicion',\n",
    "\n",
    "        'Sample Form' :'SampleForm',\n",
    "\n",
    "        'Has the Service User or a close friend tried this batch?' : 'AlreadyTried',\n",
    "\n",
    "        'Your initials' : 'Tester',\n",
    "        'Your name and first initial' : 'Tester',\n",
    "        'Your name and surname initial' : 'Tester'\n",
    "    }\n",
    "    df.rename(columns=d, inplace=True)\n",
    "    \n",
    "    def fix_timestamp(x):\n",
    "        \"\"\"Horror to fix mixed date formats\"\"\"\n",
    "        return pd.to_datetime(str(x), format='%d/%m/%Y %H:%M:%S')\n",
    "#         try:\n",
    "#             x = pd.to_datetime(x)\n",
    "#         except:\n",
    "#             try:\n",
    "#                 # '12/08/2018 12:26:15'\n",
    "#                 x = pd.to_datetime(x, format='%d/%m/%Y %H:%M:%S')\n",
    "#             except:\n",
    "#                 #'Thu 9/08 - 12:19'\n",
    "#                 x = pd.to_datetime(x, format='%a %m/%y - %H:%M')\n",
    "#         return x\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df.loc[:, 'Timestamp'] = df['Timestamp'].map(fix_timestamp)\n",
    "    df.loc[:, 'SampleNumber'] = df['SampleNumber'].apply(fix_sample_number)\n",
    "    df.dropna(subset=['SampleNumber'])\n",
    "    #df.sort_values(['Sample Number'], ascending=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_data(service, SPREADSHEET_ID):\n",
    "\n",
    "    CATALOG_RANGE = 'Catalog!A:R'\n",
    "    FTIR_RANGE = 'FTIR!A:X'\n",
    "    REAGENT_RANGE = 'Reagent!A:W'\n",
    "    MLA_RANGE = 'MLA!A:R'\n",
    "    HR_RANGE = 'Interventions!A:BJ'\n",
    "\n",
    "    #service = gsheets_service()\n",
    "\n",
    "    df_catalog = get_df(service, SPREADSHEET_ID, CATALOG_RANGE)\n",
    "    df_catalog = canonicalise_df(df_catalog, source='catalog')\n",
    "    df_ftir = get_df(service, SPREADSHEET_ID, FTIR_RANGE)\n",
    "    df_ftir = canonicalise_df(df_ftir, source='ftir')\n",
    "    df_reagent = get_df(service, SPREADSHEET_ID, REAGENT_RANGE)\n",
    "    df_reagent = canonicalise_df(df_reagent, source='reagent')\n",
    "    df_mla = get_df(service, SPREADSHEET_ID, MLA_RANGE, mla=True)\n",
    "    df_mla = canonicalise_df(df_mla, source='mla')\n",
    "    try:\n",
    "        df_hr = get_df(service, SPREADSHEET_ID, HR_RANGE)\n",
    "    except ValueError:\n",
    "        df_hr = None\n",
    "    if df_hr is not None:\n",
    "        df_hr = canonicalise_df(df_hr, source='hr')\n",
    "\n",
    "    df = DataFrames()\n",
    "    df.catalog=df_catalog\n",
    "    df.ftir=df_ftir\n",
    "    df.reagent=df_reagent\n",
    "    df.mla=df_mla\n",
    "    df.hr=df_hr\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "BOOMTOWN2018_SPREADSHEET_ID = '1RiA-FwG_954Ger2VPsOSA3JLh-7sEoTYr40eVS0mp24'\n",
    "MADE2018_SPREADSHEET_ID = '1daXdyL6uL8qnMsEsP0RLZE9nDzt6J7Zr1ygQdguvi-E'\n",
    "BOARDMASTERS2018_SPREADSHEET_ID = '1U1lhUWLazDBN-wb2eZM8YV674f46npVfQK3XUVZjPow'\n",
    "SW42018_SPREADSHEET_ID = '1agpMmJ9XukeWXS5_mwrDSKeshUaFtYwOzsPiR1DKsPU'\n",
    "LOSTVILLAGE2018_SPREADSHEET_ID = '1OL0gyXrpZnJ8e7yR7eF6S2OaBYBiPDoVp5xGpdK4wlA'\n",
    "BESTIVAL2018_SPREADSHEET_ID = '184qudGcw4PB0SMtOo0ZBDtckeGaH0RCLUXbA-u3BiHE'\n",
    "YNOT2018_SPREADSHEET_ID = '1D01cj-Mra06TuoG_MsKuLq9OdtvKzrvRdiE255po_ag'\n",
    "TRUCKFEST2018_SPREADSHEET_ID = '1sGG9WJxKyD2CGUjzJAXul3g9hVnRz6HbTiqKV5cUAyA'\n",
    "LSTD2018_SPREADSHEET_ID = '1R8YqDnrhvuVMwPFShwaaAUIyCXQMeozA230OXsFsDQM'\n",
    "KENDALCALLING2018_SPREADSHEET_ID = '16-PfwBOaUxwod3X75LGk1VAjBblkNsTJpCsX825aghI'\n",
    "PARKLIFE2018_SPREADSHEET_ID = '1oO5sHcUhUn_7M1Hap73sOZHNEfWFMcDkQuWDRFf4d-w'\n",
    "\n",
    "\n",
    "data = {}\n",
    "service = gsheets_service()\n",
    "# print \"PROCESSING BOOMTOWN\"\n",
    "# data['boomtown'] = get_data(service, BOOMTOWN2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BOARDMASTERS\"\n",
    "# data['boardmasters'] = get_data(service, BOARDMASTERS2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING MADE\"\n",
    "# data['made'] = get_data(service, MADE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING SW4\"\n",
    "# data['sw4'] = get_data(service, SW42018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LOST VILLAGE\"\n",
    "# data['lostvillage'] = get_data(service, LOSTVILLAGE2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING BESTIVAL\"\n",
    "# data['bestival'] = get_data(service, BESTIVAL2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING YNOT\"\n",
    "# data['ynot'] = get_data(service, YNOT2018_SPREADSHEET_ID)\n",
    "print \"PROCESSING TRUCKFEST\"\n",
    "data['truckfest'] = get_data(service, TRUCKFEST2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING LSTD\"\n",
    "# data['lstd'] = get_data(service, LSTD2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING KENDAL CALLING\"\n",
    "# data['kc'] = get_data(service, KENDALCALLING2018_SPREADSHEET_ID)\n",
    "# print \"PROCESSING PARKLIFE\"\n",
    "# data['parklife'] = get_data(service, PARKLIFE2018_SPREADSHEET_ID)\n",
    "\n",
    "import pickle\n",
    "with open('foo_multi.pkl','w') as w:\n",
    "    pickle.dump(data, w)\n",
    "    \n",
    "dfs = data['truckfest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1 duplicated catalog SampleNumbers ['A0020'] ###\n",
      "Please fix duplicated values\n"
     ]
    }
   ],
   "source": [
    "# with open('foo_multi.pkl') as f:\n",
    "#     data = pickle.load(f)\n",
    "# dfs = data['boomtown']\n",
    "\n",
    "# Check for duplicates\n",
    "catalog_duplicates = dfs.catalog['SampleNumber'].duplicated()\n",
    "if catalog_duplicates.any():\n",
    "    catalog_duplicates = list(dfs.catalog.loc[catalog_duplicates, 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated catalog SampleNumbers %s ###\" % (len(catalog_duplicates), catalog_duplicates))\n",
    "    dfs.catalog[dfs.catalog['SampleNumber'].duplicated(keep=False)].to_csv('catalog_duplicates.csv')\n",
    "else:\n",
    "    catalog_duplicates = None\n",
    "    \n",
    "ftir_duplicates = dfs.ftir['SampleNumber'].duplicated()\n",
    "if ftir_duplicates.any():\n",
    "    ftir_duplicates = list(dfs.ftir.loc[dfs.ftir['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated FTIR SampleNumbers %s ###\" % (len(ftir_duplicates), ftir_duplicates))\n",
    "    dfs.ftir[dfs.ftir['SampleNumber'].duplicated(keep=False)].to_csv('ftir_duplicates.csv')\n",
    "else:\n",
    "    ftir_duplicates = None\n",
    "\n",
    "reagent_duplicates = dfs.reagent['SampleNumber'].duplicated()\n",
    "if reagent_duplicates.any():\n",
    "    reagent_duplicates = list(dfs.reagent.loc[dfs.reagent['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated reagent SampleNumbers %s ###\" % (len(reagent_duplicates), reagent_duplicates))    \n",
    "    dfs.reagent[dfs.reagent['SampleNumber'].duplicated(keep=False)].to_csv('reagent_duplicates.csv', encoding = 'utf-8')\n",
    "else:\n",
    "    reagent_duplicates = None\n",
    "\n",
    "hr_duplicates = None\n",
    "if dfs.hr is not None:\n",
    "    hr_duplicates = dfs.hr['SampleNumber'].duplicated()\n",
    "    if hr_duplicates.any():\n",
    "        hr_duplicates = list(dfs.hr.loc[dfs.hr['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "        print(\"### %d duplicated HR SampleNumbers %s ###\" % (len(hr_duplicates), hr_duplicates))\n",
    "        dfs.hr[dfs.hr['SampleNumber'].duplicated(keep=False)].to_csv('hr_duplicates.csv', encoding = 'utf-8')\n",
    "    else:\n",
    "        hr_duplicates = None\n",
    "\n",
    "mla_duplicates = dfs.mla['SampleNumber'].duplicated()\n",
    "if mla_duplicates.any():\n",
    "    mla_duplicates = list(dfs.mla.loc[dfs.mla['SampleNumber'].duplicated(), 'SampleNumber'].values)\n",
    "    print(\"### %d duplicated MLA SampleNumbers %s ###\" % (len(mla_duplicates), mla_duplicates))\n",
    "    dfs.mla[dfs.mla['SampleNumber'].duplicated(keep=False)].to_csv('mla_duplicates.csv')\n",
    "else:\n",
    "    mla_duplicates = None\n",
    "    \n",
    "if catalog_duplicates or \\\n",
    "    ftir_duplicates or \\\n",
    "    reagent_duplicates or \\\n",
    "    hr_duplicates or \\\n",
    "    mla_duplicates:\n",
    "    outs = 'Please fix duplicated values'\n",
    "    print(outs)\n",
    "#     raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Timestamp SampleNumber     Tester            SampleSource  \\\n",
      "0  2018-07-20 16:58:55        A0005   KARINA N  Security/Police direct   \n",
      "1  2018-07-20 13:53:21        A0007      ABI A  Security/Police direct   \n",
      "2  2018-07-20 13:55:14        A0008      ABI A  Security/Police direct   \n",
      "3  2018-07-20 13:57:42        A0009      ABI A  Security/Police direct   \n",
      "4  2018-07-20 13:59:41        A0010      ABI A  Security/Police direct   \n",
      "5  2018-07-20 14:08:50        A0011      BReed                 Amnesty   \n",
      "6  2018-07-20 14:12:50        A0012      BReed                 Amnesty   \n",
      "7  2018-07-21 15:11:31        A0013      BReed  Security/Police direct   \n",
      "8  2018-07-21 15:16:12        A0014   KARINA N  Security/Police direct   \n",
      "9  2018-07-21 15:21:24        A0015   KARINA N  Security/Police direct   \n",
      "10 2018-07-21 15:24:22        A0016   KARINA N  Security/Police direct   \n",
      "11 2018-07-21 15:27:25        A0017   KARINA N  Security/Police direct   \n",
      "12 2018-07-21 15:28:36        A0020   KARINA N  Security/Police direct   \n",
      "13 2018-07-21 15:30:04        A0018   KARINA N  Security/Police direct   \n",
      "14 2018-07-21 15:31:09        A0020   KARINA N  Security/Police direct   \n",
      "15 2018-07-21 15:32:33        A0023   KARINA N  Security/Police direct   \n",
      "16 2018-07-21 15:34:47        A0025   KARINA N  Security/Police direct   \n",
      "17 2018-07-21 15:35:30        A0024             Security/Police direct   \n",
      "18 2018-07-21 15:36:43        A0027   KARINA N  Security/Police direct   \n",
      "19 2018-07-21 15:39:23        A0021  KARINA N   Security/Police direct   \n",
      "20 2018-07-21 15:39:54        A0028   KARINA N  Security/Police direct   \n",
      "21 2018-07-21 15:43:54        A0026  KARINA N   Security/Police direct   \n",
      "22 2018-07-21 15:45:27        A0030   KARINA N  Security/Police direct   \n",
      "23 2018-07-21 15:47:34        A0019      ABI A  Security/Police direct   \n",
      "24 2018-07-21 15:49:25        A0029      ABI A  Security/Police direct   \n",
      "25 2018-07-21 15:52:07        A0031      A0031  Security/Police direct   \n",
      "26 2018-07-21 15:53:30        A0032      ABI A  Security/Police direct   \n",
      "27 2018-07-21 15:54:28        A0033      ABI A  Security/Police direct   \n",
      "28 2018-07-21 15:55:57        A0034      ABI A  Security/Police direct   \n",
      "29 2018-07-21 15:56:34        A0035      ABI A  Security/Police direct   \n",
      "30 2018-07-21 15:58:08        A0036      ABI A  Security/Police direct   \n",
      "31 2018-07-21 15:58:47        A0037      ABI A  Security/Police direct   \n",
      "32 2018-07-21 16:35:48        F0038       Jens  Security/Police direct   \n",
      "33 2018-07-22 10:33:55        A0039      Abi A                 Welfare   \n",
      "34 2018-07-22 10:35:39        A0040      Abi A                 Welfare   \n",
      "\n",
      "                          SoldAs AlreadyTried  \\\n",
      "0   Found or otherwise not known           No   \n",
      "1   Found or otherwise not known           No   \n",
      "2   Found or otherwise not known           No   \n",
      "3   Found or otherwise not known           No   \n",
      "4   Found or otherwise not known           No   \n",
      "5   Found or otherwise not known           No   \n",
      "6   Found or otherwise not known           No   \n",
      "7   Found or otherwise not known           No   \n",
      "8   Found or otherwise not known           No   \n",
      "9   Found or otherwise not known           No   \n",
      "10  Found or otherwise not known           No   \n",
      "11  Found or otherwise not known           No   \n",
      "12  Found or otherwise not known           No   \n",
      "13  Found or otherwise not known           No   \n",
      "14  Found or otherwise not known           No   \n",
      "15  Found or otherwise not known           No   \n",
      "16  Found or otherwise not known           No   \n",
      "17  Found or otherwise not known           No   \n",
      "18  Found or otherwise not known           No   \n",
      "19  Found or otherwise not known           No   \n",
      "20  Found or otherwise not known           No   \n",
      "21  Found or otherwise not known           No   \n",
      "22  Found or otherwise not known           No   \n",
      "23  Found or otherwise not known           No   \n",
      "24  Found or otherwise not known           No   \n",
      "25  Found or otherwise not known           No   \n",
      "26  Found or otherwise not known           No   \n",
      "27  Found or otherwise not known           No   \n",
      "28  Found or otherwise not known           No   \n",
      "29  Found or otherwise not known           No   \n",
      "30  Found or otherwise not known           No   \n",
      "31  Found or otherwise not known           No   \n",
      "32           Crushed paracetamol           No   \n",
      "33  Found or otherwise not known          Yes   \n",
      "34                          MDMA          Yes   \n",
      "\n",
      "                                        UserSuspicion  \\\n",
      "0                                                       \n",
      "1                                                       \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "5                                                       \n",
      "6                                                       \n",
      "7                                                       \n",
      "8                                                       \n",
      "9                                                       \n",
      "10                                                      \n",
      "11                                                      \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                                                      \n",
      "15                                                      \n",
      "16                                                      \n",
      "17                                                      \n",
      "18                                                      \n",
      "19                                                      \n",
      "20                                                      \n",
      "21                                                      \n",
      "22                                                      \n",
      "23                                                      \n",
      "24                                                      \n",
      "25                                                      \n",
      "26                                                      \n",
      "27                                                      \n",
      "28                                                      \n",
      "29                                                      \n",
      "30                                                      \n",
      "31                                                      \n",
      "32                                                      \n",
      "33  From welfare, user was concerned and experienc...   \n",
      "34  From welfare, user was concerned and experienc...   \n",
      "\n",
      "                     SampleForm             What is the logo?    \\\n",
      "0                  Ecstasy pill                         Fanta     \n",
      "1                  Ecstasy pill                        Trophy     \n",
      "2                  Ecstasy pill  Whatsapp Phone Speech Bubble     \n",
      "3                Pharmaceutical                        V MOG5     \n",
      "4                  Ecstasy pill                         Skype     \n",
      "5                  Ecstasy pill                      Heineken     \n",
      "6                Pharmaceutical                            MS     \n",
      "7   Powder/capsule/bomb/crystal                                   \n",
      "8                  Ecstasy pill                Medusa Versace     \n",
      "9   Powder/capsule/bomb/crystal                                   \n",
      "10                 Ecstasy pill                    Soundcloud     \n",
      "11                 Ecstasy pill            Whatsapp Telephone     \n",
      "12  Powder/capsule/bomb/crystal                                   \n",
      "13  Powder/capsule/bomb/crystal                                   \n",
      "14  Powder/capsule/bomb/crystal                                   \n",
      "15  Powder/capsule/bomb/crystal                                   \n",
      "16  Powder/capsule/bomb/crystal                                   \n",
      "17  Powder/capsule/bomb/crystal                                   \n",
      "18  Powder/capsule/bomb/crystal                                   \n",
      "19                 Ecstasy pill          Stone Island Compass     \n",
      "20  Powder/capsule/bomb/crystal                                   \n",
      "21         Partial ecstasy pill                          Hulk     \n",
      "22                 Ecstasy pill             Doctor Who/Tardis     \n",
      "23                 Ecstasy pill                     100 Emoji     \n",
      "24                 Ecstasy pill                     Red Bull      \n",
      "25                 Ecstasy pill                     Xanax 666     \n",
      "26                 Ecstasy pill                          M&Ms     \n",
      "27  Powder/capsule/bomb/crystal                                   \n",
      "28  Powder/capsule/bomb/crystal                                   \n",
      "29  Powder/capsule/bomb/crystal                                   \n",
      "30  Powder/capsule/bomb/crystal                                   \n",
      "31  Powder/capsule/bomb/crystal                                   \n",
      "32  Powder/capsule/bomb/crystal                                   \n",
      "33  Powder/capsule/bomb/crystal                                   \n",
      "34         Partial ecstasy pill                         Hulk      \n",
      "\n",
      "   Which device was a photo taken with? Who does it belong to?  \\\n",
      "0                                        Jens's phone            \n",
      "1                                         Loop Camera            \n",
      "2                                         Loop Camera            \n",
      "3                                         Loop Camera            \n",
      "4                                         Loop Camera            \n",
      "5                                         Loop Camera            \n",
      "6                                         Loop Camera            \n",
      "7                                                                \n",
      "8                                         Loop Camera            \n",
      "9                                                                \n",
      "10                                        Loop Camera            \n",
      "11                                        Loop Camera            \n",
      "12                                                               \n",
      "13                                                               \n",
      "14                                                               \n",
      "15                                                               \n",
      "16                                                               \n",
      "17                                                               \n",
      "18                                                               \n",
      "19                                        Loop Camera            \n",
      "20                                                               \n",
      "21                                        Loop Camera            \n",
      "22                                        Loop Camera            \n",
      "23                                        Loop Camera            \n",
      "24                                        Loop Camera            \n",
      "25                                        Loop Camera            \n",
      "26                                        Loop Camera            \n",
      "27                                                               \n",
      "28                                                               \n",
      "29                                                               \n",
      "30                                                               \n",
      "31                                                               \n",
      "32                                                               \n",
      "33                                                               \n",
      "34                                        Loop Camera            \n",
      "\n",
      "   What is the mass? (mg) What is the shape of the pill?  \\\n",
      "0                     483                       Circular   \n",
      "1                     611                         TROPHY   \n",
      "2                     344                Cut-out of logo   \n",
      "3                     553                       Circular   \n",
      "4                     516                Cut-out of logo   \n",
      "5                     376             Square/Rectangular   \n",
      "6                     196                       Circular   \n",
      "7                                                          \n",
      "8                     401                       Circular   \n",
      "9                                                          \n",
      "10                    320                          CLOUD   \n",
      "11                    350                  SPEECH BUBBLE   \n",
      "12                                                         \n",
      "13                                                         \n",
      "14                                                         \n",
      "15                                                         \n",
      "16                                                         \n",
      "17                                                         \n",
      "18                                                         \n",
      "19                    500             Square/Rectangular   \n",
      "20                                                         \n",
      "21                    820                     IRREGULAR    \n",
      "22                    450                Cut-out of logo   \n",
      "23                    440                Cut-out of logo   \n",
      "24                    500             Square/Rectangular   \n",
      "25                    150             Square/Rectangular   \n",
      "26                    540                Cut-out of logo   \n",
      "27                                                         \n",
      "28                                                         \n",
      "29                                                         \n",
      "30                                                         \n",
      "31                                                         \n",
      "32                                                         \n",
      "33                                                         \n",
      "34                    420                Cut-out of logo   \n",
      "\n",
      "   Is a breakline present? Unusual appearance What colour is the pill?  \\\n",
      "0                      Yes                                      Orange   \n",
      "1                       No        Fluorescent                   Orange   \n",
      "2                       No        Fluorescent                    Green   \n",
      "3                      Yes                                       White   \n",
      "4                      Yes    NL LOGO ON BACK               WHITE BLUE   \n",
      "5                      Yes     Pastel, grainy                    Green   \n",
      "6                      Yes             Pastel                     Blue   \n",
      "7                                                                        \n",
      "8                       No        Fluorescent                     Pink   \n",
      "9                                                                        \n",
      "10                     Yes        Fluorescent                   Orange   \n",
      "11                      No                                       Green   \n",
      "12                                                                       \n",
      "13                                                                       \n",
      "14                                                                       \n",
      "15                                                                       \n",
      "16                                                                       \n",
      "17                                                                       \n",
      "18                                                                       \n",
      "19                     Yes             PASTEL                   Yellow   \n",
      "20                                                                       \n",
      "21                     Yes        Fluorescent                   Orange   \n",
      "22                      No                                        Blue   \n",
      "23                      No        Fluorescent                   Orange   \n",
      "24                     Yes        Fluorescent                     Pink   \n",
      "25                     Yes                                       White   \n",
      "26                     Yes                                  PINK WHITE   \n",
      "27                                                                       \n",
      "28                                                                       \n",
      "29                                                                       \n",
      "30                                                                       \n",
      "31                                                                       \n",
      "32                                                                       \n",
      "33                                                                       \n",
      "34                     Yes        Fluorescent                   Orange   \n",
      "\n",
      "                                   Photo Filename  \n",
      "0                         A0005-TF18 Orange Fanta  \n",
      "1                        A0007-TF18 Orange Trophy  \n",
      "2   A0008-TF18 Green Whatsapp Phone Speech Bubble  \n",
      "3                         A0009-TF18 White V MOG5  \n",
      "4                     A0010-TF18 White Blue Skype  \n",
      "5                       A0011-TF18 Green Heineken  \n",
      "6                              A0012-TF18 Blue MS  \n",
      "7                                    A0013-TF18    \n",
      "8                  A0014-TF18 Pink Medusa Versace  \n",
      "9                                    A0015-TF18    \n",
      "10                   A0016-TF18 Orange Soundcloud  \n",
      "11            A0017-TF18 Green Whatsapp Telephone  \n",
      "12                                   A0020-TF18    \n",
      "13                                   A0018-TF18    \n",
      "14                                   A0020-TF18    \n",
      "15                                   A0023-TF18    \n",
      "16                                   A0025-TF18    \n",
      "17                                   A0024-TF18    \n",
      "18                                   A0027-TF18    \n",
      "19         A0021-TF18 Yellow Stone Island Compass  \n",
      "20                                   A0028-TF18    \n",
      "21                         A0026-TF18 Orange Hulk  \n",
      "22              A0030-TF18 Blue Doctor Who/Tardis  \n",
      "23                    A0019-TF18 Orange 100 Emoji  \n",
      "24                       A0029-TF18 Pink Red Bull  \n",
      "25                     A0031-TF18 White Xanax 666  \n",
      "26                     A0032-TF18 Pink White M&Ms  \n",
      "27                                   A0033-TF18    \n",
      "28                                   A0034-TF18    \n",
      "29                                   A0035-TF18    \n",
      "30                                   A0036-TF18    \n",
      "31                                   A0037-TF18    \n",
      "32                                   F0038-TF18    \n",
      "33                                   A0039-TF18    \n",
      "34                         A0040-TF18 Orange Hulk  \n"
     ]
    }
   ],
   "source": [
    "print dfs.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphaned FTIR SampleNumbers: ['A0006', 'A0022', 'A0038']\n",
      "Orphaned Reagent Test SampleNumbers: ['F0040']\n",
      "Orphaned catalog SampleNumbers: ['F0038']\n",
      "### Please fix orphaned/catalog only samples ###\n"
     ]
    }
   ],
   "source": [
    "# Check there are no SampleNumbers in any of the other spreadsheets that aren't in the cataolog sheet\n",
    "catalog_unique = set(dfs.catalog['SampleNumber'].unique())\n",
    "\n",
    "ftir_unique = set(dfs.ftir['SampleNumber'].unique())\n",
    "ftir_orphan = ftir_unique.difference(catalog_unique)\n",
    "if ftir_orphan:\n",
    "    print(\"Orphaned FTIR SampleNumbers: %s\" % sorted(ftir_orphan))\n",
    "\n",
    "reagent_unique = set(dfs.reagent['SampleNumber'].unique())\n",
    "reagent_orphan = reagent_unique.difference(catalog_unique)\n",
    "if reagent_orphan:\n",
    "    print(\"Orphaned Reagent Test SampleNumbers: %s\" % sorted(reagent_orphan))\n",
    "\n",
    "hr_orphan = None\n",
    "if dfs.hr is not None:\n",
    "    hr_unique = set(dfs.hr['SampleNumber'].unique())\n",
    "    hr_orphan = hr_unique.difference(catalog_unique)\n",
    "    if hr_orphan:\n",
    "        print(\"Orphaned HR SampleNumbers: %s\" % sorted(hr_orphan))\n",
    "    \n",
    "mla_unique = set(dfs.mla['SampleNumber'].unique()).difference(catalog_unique)\n",
    "mla_orphan = mla_unique.difference(catalog_unique)\n",
    "if mla_orphan:\n",
    "    print(\"Orphaned MLA SampleNumbers: %s\" % sorted(mla_orphan))\n",
    "    \n",
    "# Check for any that are only in the catalog\n",
    "outside_catalog = set.union(ftir_unique, reagent_unique, hr_unique, mla_unique)\n",
    "catalog_orphan = catalog_unique.difference(outside_catalog)\n",
    "if catalog_orphan:\n",
    "    print(\"Orphaned catalog SampleNumbers: %s\" % sorted(catalog_orphan))\n",
    "    \n",
    "# Check for any that aren't in FTIR and don't have anything in reagent test\n",
    "ftir_missing = catalog_unique.difference(ftir_unique).difference(reagent_unique).difference(catalog_orphan)\n",
    "if len(ftir_missing):\n",
    "    print(\"Samples not in FTIR or Reagent: %s\" % sorted(ftir_missing))\n",
    "\n",
    "all_unique = copy.copy(ftir_unique)\n",
    "all_unique.update(reagent_unique, hr_unique, mla_unique)\n",
    "if (all_unique or catalog_only):\n",
    "    outs = \"### Please fix orphaned/catalog only samples ###\"\n",
    "    print(outs)\n",
    "    #raise RuntimeError(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    sample_form_d = { 'pill' : ['Ecstasy Tablet',\n",
    "                                'ecstasy pill',\n",
    "                                'ecstacy pill',\n",
    "                                'Non-pharmaceutical tablet (ecstasy etc)',\n",
    "                                'other recreational pill',\n",
    "                                 'Whole pill',\n",
    "                                'Other pill',\n",
    "                                'Pharmaceutical'],\n",
    "                  'partial pill' : ['Partial ecstasy pill',\n",
    "                                    'Partial 2C-B pill',\n",
    "                                    'Crushed tablet'],\n",
    "                  'powder' : ['Powder/capsule/bomb/crystal',\n",
    "                              'Powder or crushed pill',\n",
    "                              'Crystal, Capsule or Powder'],\n",
    "                  'liquid' : ['*Cannabinoid liquid',\n",
    "                               '*Viscous liquid',\n",
    "                              'Dissolved in Propylene Glycol',\n",
    "                              'Oil'],\n",
    "                   'tab' : ['blotter', 'LSD Tab']\n",
    "                      }\n",
    "\n",
    "\n",
    "    # Firstly convert all columns to lower case and remove any spaces\n",
    "    def lower(value):\n",
    "        if type(value) in [str, unicode]:\n",
    "            value = value.strip().lower()\n",
    "        return value\n",
    "\n",
    "    for column in ['SampleForm']:\n",
    "        df[column] = df[column].map(lower, na_action='ignore')\n",
    "    \n",
    "    replace_d = {}\n",
    "    for column in ['SampleForm']:\n",
    "        replace_d[column] = {}\n",
    "        for drug, names in sample_form_d.items():\n",
    "            for name in names:\n",
    "                replace_d[column][name.lower()] = drug\n",
    "    \n",
    "    # Replace values\n",
    "    df.replace(replace_d, inplace=True)\n",
    "    return df\n",
    "    \n",
    "dfs.catalog = clean_df(dfs.catalog)\n",
    "dfs.ftir = clean_df(dfs.ftir)\n",
    "dfs.reagent = clean_df(dfs.reagent)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ftir <-> catalog\n",
    "\n",
    "incorrect_duplicates = []\n",
    "for each duplicate sample number:\n",
    "    see if one is definiitively wrong and add to list\n",
    "\n",
    "for each incorrect duplicate:\n",
    "    for each orphan:\n",
    "        see if this orphan could match the duplicate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTIR SampleNumber F0629 duplicate (line: 154) DIFFERENT Catalog sample (line: 162)\n",
      "['powder', u'Cocaine', u'Yes'] 2018-08-12 14:58:25\n",
      "['pill', u'MDMA', u'No'] 2018-08-12 16:27:34\n",
      "FTIR SampleNumber F0629 duplicate (line: 170) DIFFERENT Catalog sample (line: 162)\n",
      "['pill', u'MDMA', u'No'] 2018-08-12 16:31:14\n",
      "['pill', u'MDMA', u'No'] 2018-08-12 16:27:34\n"
     ]
    }
   ],
   "source": [
    "def find_duplicate_matches(duplicates, df1, df2, df1_name='DataFrame1', df2_name='DataFrame2'):\n",
    "    duplicate_matches = {}\n",
    "    min_stage_delay = 60 * 1\n",
    "    max_stage_delay = 60 * 30\n",
    "    for sample_number in duplicates:\n",
    "        duplicate_matches[sample_number] = {}\n",
    "        for i, df1_row in enumerate(df1.loc[df1['SampleNumber'] == sample_number].itertuples()):\n",
    "            for j, df2_row in enumerate(df2.loc[df2['SampleNumber'] == sample_number].itertuples()):\n",
    "                i += 1\n",
    "                j += 1\n",
    "                df1_data = [df1_row.SampleForm, df1_row.SoldAs, df1_row.AlreadyTried]\n",
    "                df1_time = df1_row.Timestamp\n",
    "                df1_idx = df1_row.Index + 1\n",
    "                df2_data = [df2_row.SampleForm, df2_row.SoldAs, df2_row.AlreadyTried]\n",
    "                df2_time = df2_row.Timestamp\n",
    "                df2_idx = df2_row.Index + 1            \n",
    "                delta_t = (df2_time - df1_time).seconds\n",
    "                if df1_data == df2_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                    print(\"%s SampleNumber %s duplicate (line: %d) MATCHES %s sample (line: %d)\" % \\\n",
    "                          (df1_name, sample_number, df1_idx, df2_name, df2_idx))\n",
    "                    duplicate_matches[sample_number][df1_row.Index] = True\n",
    "                else:\n",
    "                    print(\"%s SampleNumber %s duplicate (line: %d) DIFFERENT %s sample (line: %d)\\n%s %s\\n%s %s\" % \\\n",
    "                          (df1_name, sample_number, df1_idx, df2_name, df2_idx,\n",
    "                           df1_data, df1_time,\n",
    "                           df2_data, df2_time))\n",
    "                    duplicate_matches[sample_number][df1_row.Index] = False\n",
    "    return duplicate_matches\n",
    "\n",
    "#catalog_duplicate_matches = find_duplicate_matches(catalog_duplicates, dfs.catalog, dfs.ftir, df1_name='Catalog', df2_name='FTIR')\n",
    "\n",
    "duplicate_matches = find_duplicate_matches(ftir_duplicates, dfs.ftir, dfs.catalog, df1_name='FTIR', df2_name='Catalog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_orphans_to_duplicates(df1_orphans, duplicate_matches, df1, df2):\n",
    "    for orphan_sample_number in df1_orphans:\n",
    "        df1_data = df1.loc[df1['SampleNumber'] == orphan_sample_number, ['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']]\n",
    "        df1_data = df1_data.values.tolist()[0]\n",
    "        df1_time = df1_data.pop()\n",
    "        for sample_number, indexd in duplicate_matches.items():\n",
    "            for k, v in indexd.items():\n",
    "                if not v:\n",
    "                    df2_data = dfs.catalog.iloc[k][['SampleForm', 'SoldAs', 'AlreadyTried', 'Timestamp']].values.tolist()\n",
    "                    df2_time = df2_data.pop()\n",
    "                    delta_t = (df1_time - df2_time).seconds\n",
    "                    if df2_data == df1_data and min_stage_delay < delta_t <= max_stage_delay:\n",
    "                        print \"Orphan {} could be match for duplicate {} (line: {})\\n{} {}\\n{} {}\".format(orphan_sample_number,\n",
    "                                                                                                  sample_number, k+1,\n",
    "                                                                                                  df2_data, df2_time,\n",
    "                                                                                                  df1_data, df1_time)\n",
    "\n",
    "# match_orphans_to_duplicates(ftir_orphan, duplicate_matches, dfs.ftir, dfs.catalog)\n",
    "match_orphans_to_duplicates(catalog_orphan, duplicate_matches, dfs.catalog, dfs.ftir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up catalog\n",
    "# Drop all unwanted columns\n",
    "\n",
    "#  or 'Your initials'\n",
    "l = set(['Your initials',\n",
    "         'Your name and first initial',\n",
    "         'Which device was a photo taken with? Who does it belong to?',\n",
    "         'Is a breakline present?',\n",
    "         'Unusual appearance'\n",
    "        ])\n",
    "\n",
    "to_drop = set(dfs.catalog.columns).intersection(l)\n",
    "dfs.catalog.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "d = {\n",
    "    'Timestamp' : 'Catalog timestamp',\n",
    "    'Sample Advertised/Acquired/Sold As': 'Catalog_SoldAs',\n",
    "    'Sample Form' : 'Catalog_Form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'Catalog_Tried',\n",
    "    'What is the mass? (mg)': 'FullPillMass',\n",
    "    'What is the shape of the pill?': 'PillShape',\n",
    "    'What is the logo?': 'PillLogo',\n",
    "    'What colour is the pill?': 'PillColour'\n",
    "}\n",
    "dfs.catalog.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('COLS ', Index([                                                           u'Timestamp',\n",
      "                                                              u'Sample Number',\n",
      "                                                                     u'Tester',\n",
      "                                                                    u'Sold As',\n",
      "                                                                u'Sample Form',\n",
      "                                                              u'Already Tried',\n",
      "                                                             u'User Suspicion',\n",
      "                                                         u'Substance detected',\n",
      "                                                             u'Hit Confidence',\n",
      "                                                          u'Compound detected',\n",
      "                                                           u'Hit Confidence.1',\n",
      "                                                                 u'Brief Note',\n",
      "                           u'Is anything detected after subtraction analysis?',\n",
      "                                            u'Compound detected (Subtraction)',\n",
      "                                                           u'Hit Confidence.2',\n",
      "                                                       u'Substance detected.1',\n",
      "                                                           u'Hit Confidence.3',\n",
      "                                                               u'Brief Note.1',\n",
      "                                                             u'Next action(s)',\n",
      "                                                      u'Substance(s) detected',\n",
      "                                           u'\"Strength\" of powdered substance',\n",
      "       u'Does the substance detected match the substance that was advertised?',\n",
      "                                             u'Note for harm reduction worker',\n",
      "                                                            u'Send to HR team'],\n",
      "      dtype='object'))\n",
      "('SS ', 1691    N-Ethylpentylone\n",
      "1692    N-Ethylpentylone\n",
      "1694    N-Ethylpentylone\n",
      "1696             Cocaine\n",
      "0                   MDMA\n",
      "Name: Substance detected, dtype: object)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_ftir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f76c2c2a13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Compound detected (Subtraction)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_ftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Copy values from 'Compound detected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mftir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Substance detected.1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hit Confidence.3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Brief Note.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ftir' is not defined"
     ]
    }
   ],
   "source": [
    "# For FTIR columns need to merge the data from the 'Compound detected', 'Hit Confidence.1' columns into the\n",
    "# 'Substance detected', 'Hit Confidence' column where the substance detected was 'other'\n",
    "print(\"COLS \",dfs.ftir.columns)\n",
    "print(\"SS \",dfs.ftir['Substance detected'][:5])\n",
    "mask = dfs.ftir['Substance detected'] != 'Other'\n",
    "dfs.ftir['Substance detected'].where(mask, dfs.ftir['Compound detected'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence'].where(mask, dfs.ftir['Hit Confidence.1'], inplace=True)\n",
    "dfs.ftir.drop(['Compound detected', 'Hit Confidence.1', 'Brief Note'], axis=1, inplace=True)\n",
    "\n",
    "mask = dfs.ftir['Compound detected (Subtraction)'] != 'Other'\n",
    "dfs.ftir['Compound detected (Subtraction)'].where(mask, df_ftir['Substance detected.1'], inplace=True) # Copy values from 'Compound detected'\n",
    "dfs.ftir['Hit Confidence.2'].where(mask, dfs.ftir['Hit Confidence.3'], inplace=True)\n",
    "dfs.ftir.drop(['Substance detected.1', 'Hit Confidence.3', 'Brief Note.1'], axis=1, inplace=True)\n",
    "\n",
    "#Drop all unwanted columns\n",
    "l = ['Your name and surname initial',\n",
    "     'User Suspicion',\n",
    "     'Is anything detected after subtraction analysis?',\n",
    "     'Analysis required', \n",
    "     'Next action(s)',\n",
    "     'Send to HR team'\n",
    "    ]\n",
    "#'Note for harm reduction worker'\n",
    "to_drop = set(dfs.ftir.columns).intersection(l)\n",
    "dfs.ftir.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'FTIR timestamp',\n",
    "    'Sample Sold As': 'FTIR Sold As',\n",
    "    'Sample Form' : 'FTIR form',\n",
    "    'Has the Service User or a close friend tried this batch?': 'FTIR tried',\n",
    "    'Substance(s) detected' : 'FTIR final result',\n",
    "    'Substance detected' : 'FTIR result1',\n",
    "    'Hit Confidence' :  'FTIR hit1',\n",
    "    'Is anything detected after subtraction analysis?' : 'FTIR subtraction positive',\n",
    "    'Compound detected (Subtraction)' :  'FTIR result2',\n",
    "    'Hit Confidence.2' :  'FTIR hit2',\n",
    "    '\"Strength\" of powdered substance' : 'FTIR Powder Strength',\n",
    "    'Does the substance detected match the substance that was advertised?' : 'FTIR Matches Sold As',\n",
    "}\n",
    "dfs.ftir.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up HR form\n",
    "\n",
    "# Drop all unwanted columns\n",
    "l = ['HR worker name:']\n",
    "dfs.hr.drop(l, axis=1, inplace=True)\n",
    "\n",
    "# Rename shared columns so that we can check for any errors and remove any columns not of interest to the master df\n",
    "d = {\n",
    "    'Timestamp' : 'HR timestamp',\n",
    "    'You submitted a substance for analysis. What were you told it was when you got it?': 'HR Sold as',\n",
    "    'Had you already tried this substance before getting it tested?': 'HR tried',\n",
    "    'What was your first sample number at this event? Did you take a photo or keep the ticket?': 'Previous Sample Number'\n",
    "}\n",
    "dfs.hr.rename(columns=d, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Catalog and FTIR data frames\n",
    "df_all = pd.merge(dfs.catalog, dfs.ftir, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any reagent test data\n",
    "df_all = pd.merge(df_all, dfs.reagent[['Sample Number', 'Reagent Result']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in any pill strength data\n",
    "df_all = pd.merge(df_all, dfs.mla[['Sample Number', 'MDMA / tablet (mg)', '% MDMA content']], how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in HR data\n",
    "df_all = pd.merge(df_all, dfs.hr, how='left', on=['Sample Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix column orders\n",
    "prefix = ['Sample Number',\n",
    "          'Catalog timestamp', 'FTIR timestamp', 'HR timestamp',\n",
    "          'Catalog Sold As', 'FTIR Sold As','HR Sold as', \n",
    "          'Catalog form', 'FTIR form',\n",
    "          'Catalog tried', 'FTIR tried', 'HR tried']\n",
    "columns = [c for c in df_all.columns if c not in prefix]\n",
    "columns = prefix + columns\n",
    "df_all = df_all[columns]\n",
    "df_all.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
